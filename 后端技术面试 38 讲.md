# 后端技术面试 38 讲

### 开篇词 | 掌握软件开发技术的第一性原理

太阳底下没有新鲜事，绝大多数新技术其实都脱胎于一些既有的技术体系。

如果你能建立起这套技术思维体系，掌握这套技术体系背后的原理，那么当你接触一个新技术的时候，就可以快速把握住这个新技术的本质特征和思路方法，然后用你的技术思维体系快速推导出这个新技术是如何实现的。这个时候你其实不需要去学习这个新技术了，而是去验证这个新技术，你会去看它的文档和代码，去验证它是不是和你推导、猜测的实现方式一致，而不是去学习它怎么用了。

物理学有一个第一性原理， 指的是根据一些最基本的物理学常量，从头进行物理学的推导，进而得到整个物理学体系。

第一性原理就是让我们抓住事物最本质的特征原理，依据事物本身的规律，去推导、分析、演绎事物的各种变化规律，进而洞悉事物在各种具体场景下的表现形式，而不是追随事物的表面现象，生搬硬套各种所谓的规矩、经验和技巧，以至于在各种纷繁复杂的冲突和纠结中迷失了方向。

第一性原理是一种思维方式，一种学习方式，一种围绕事物核心推动事物正确前进的做事方式。

### 01 | 程序运行原理：程序是如何运行又是如何崩溃的？

### 02 | 数据结构原理：Hash 表的时间复杂度为什么是 O(1)？

数组是最常用的数据结构，创建数组必须要内存中一块连续的空间，并且数组中必须存放相同的数据类型。

由于每个整型数据占据 4 个字节的内存空间，因此整个数组的内存空间地址是 1000～1039，根据这个，我们就可以轻易算出数组中每个数据的内存下标地址。利用这个特性，我们只要知道了数组下标，也就是数据在数组中的位置，比如下标 2，就可以计算得到这个数据在内存中的位置 1008，从而对这个位置的数据进行快速读写访问，时间复杂度为 O(1)。

随机快速读写是数组的一个重要特性，但是要随机访问数据，必须知道数据在数组中的下标。如果我们只是知道数据的值，想要在数组中找到这个值，那么就只能遍历整个数组，时间复杂度为 O(N)。

Hash 表的物理存储其实是一个数组，如果我们能够根据 Key 计算出数组下标，那么就可以快速在数组中查找到需要的 Key 和 Value。许多编程语言支持获得任意对象的 HashCode，比如 Java 语言中 HashCode 方法包含在根对象 Object 中，其返回值是一个 Int。我们可以利用这个 Int 类型的 HashCode 计算数组下标。最简单的方法就是余数法，使用 Hash 表的数组长度对 HashCode 求余， 余数即为 Hash 表数组的下标，使用这个下标就可以直接访问得到 Hash 表中存储的 Key、Value。

不同的 Key 有可能计算得到相同的数组下标，这就是所谓的 Hash 冲突，解决 Hash 冲突常用的方法是链表法。

### 03 | Java 虚拟机原理：JVM 为什么被称为机器（machine）？

### 04 | 网络编程原理：一个字符的互联网之旅

数据链路层就是将数据进行封装后交给物理层进行传输，主要就是将数据封装成数据帧，以帧为单位通过物理层进行通信，有了帧，就可以在帧上进行数据校验，进行流量控制。数据链路层会定义帧的大小，这个大小也被称为最大传输单元。

链路层负载均衡（LVS）

这种负载均衡模式也叫直接路由模式，在负载均衡服务器的 Linux 操作系统内核拿到数据包后，直接修改数据帧中的 mac 地址，将其修改为搜索服务器集群中某个服务器的 mac 地址，然后将数据重新发送回服务器集群所在的局域网，这个数据帧就会被某个真实的搜索服务器接收到。

负载均衡服务器和集群内的搜索服务器配置相同的虚拟 IP 地址，也就是说，在网络通信的 IP 层面，负载均衡服务器变更 mac 地址的操作是透明的，不影响 TCP/IP 的通信连接。所以真实的搜索服务器处理完搜索请求，发送应答响应的时候，就会直接发送回请求的 App 手机，不会再经过负载均衡服务器。

### 05 | 文件系统原理：如何用 1 分钟遍历一个 100TB 的文件？

文件系统

文件系统将硬盘空间以块为单位进行划分，每个文件占据若干个块，然后再通过一个文件控制块 FCB 记录每个文件占据的硬盘数据块。

这个文件控制块在 Linux 操作系统中就是 inode，要想访问文件，就必须获得文件的 inode 信息，在 inode 中查找文件数据块索引表，根据索引中记录的硬盘地址信息访问硬盘，读写数据。

inode 中记录着文件权限、所有者、修改时间和文件大小等文件属性信息，以及文件数据块硬盘地址索引。inode 是固定结构的，能够记录的硬盘地址索引数也是固定的，只有 15 个索引。其中前 12 个索引直接记录数据块地址，第 13 个索引记录索引地址，也就是说，索引块指向的硬盘数据块并不直接记录文件数据，而是记录文件数据块的索引表，每个索引表可以记录 256 个索引；第 14 个索引记录二级索引地址，第 15 个索引记录三级索引地址，如下图：

![inode 文件控制块](https://github.com/songor/interview/blob/master/picture/inode%20%E6%96%87%E4%BB%B6%E6%8E%A7%E5%88%B6%E5%9D%97.jpg)

这样，每个 inode 最多可以存储 12+256+256\*256+256\*256\*256 个数据块，如果每个数据块的大小为 4k，也就是单个文件最大不超过 70G，而且即使可以扩大数据块大小，文件大小也要受单个硬盘容量的限制。

RAID

RAID，即独立硬盘冗余阵列，将多块硬盘通过硬件 RAID 或者软件 RAID 的方案管理起来，使其共同对外提供服务。RAID 的核心思路其实是利用文件系统将数据写入硬盘中不同数据块的特性，将多块硬盘上的空闲空间看做一个整体进行数据写入，也就是说，一个文件的多个数据块可能写入多个硬盘。

根据硬盘组织和使用方式不同，常用 RAID 有五种，分别是 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。

RAID 0 将一个文件的数据分成 N 片，同时向 N 个硬盘写入，这样单个文件可以存储在 N 个硬盘上，文件容量可以扩大 N 倍，（理论上）读写速度也可以扩大 N 倍。但是使用 RAID 0 的最大问题是文件数据分散在 N 块硬盘上，任何一块硬盘损坏，就会导致数据不完整，整个文件系统全部损坏，文件的可用性极大地降低了。

RAID 1 则是利用两块硬盘进行数据备份，文件同时向两块硬盘写入，这样任何一块硬盘损坏都不会出现文件数据丢失的情况，文件的可用性得到提升。

RAID 10 结合 RAID 0 和 RAID 1，将多块硬盘进行两两分组，文件数据分成 N 片，每个分组写入一片，每个分组内的两块硬盘再进行数据备份。这样既扩大了文件的容量，又提高了文件的可用性。但是这种方式硬盘的利用率只有 50%，有一半的硬盘被用来做数据备份。

RAID 5 针对 RAID 10 硬盘浪费的情况，将数据分成 N-1 片，再利用这 N-1 片数据进行位运算，计算一片校验数据，然后将这 N 片数据写入 N 个硬盘。这样任何一块硬盘损坏，都可以利用校验片的数据和其他数据进行计算得到这片丢失的数据，而硬盘的利用率也提高到 N-1/N。

RAID 5 可以解决一块硬盘损坏后文件不可用的问题，那么如果两块硬盘损坏呢？RAID 6 的解决方案是，用两种位运算校验算法计算两片校验数据，这样两块硬盘损坏还是可以计算得到丢失的数据片。

实践中，使用最多的是 RAID 5，数据被分成 N-1 片并发写入 N-1 块硬盘，这样既可以得到较好的硬盘利用率，也能得到很好的读写速度，同时还能保证较好的数据可用性。使用 RAID 5 的文件系统比简单的文件系统文件容量和读写速度都提高了 N-1 倍，但是一台服务器上能插入的硬盘数量是有限的，通常是 8 块，也就是文件读写速度和存储容量提高了 7 倍，这远远达不到 1 分钟完成 100T 文件的遍历要求。

分布式文件系统

Linux 的文件系统：文件的基本信息，也就是文件元信息记录在文件控制块 inode 中，文件的数据记录在硬盘的数据块中，inode 通过索引记录数据块的地址，读写文件的时候，查询 inode 中的索引记录得到数据块的硬盘地址，然后访问数据。

如果将数据块的地址改成分布式服务器的地址呢？也就是查询得到的数据块地址不只是本机的硬盘地址，还可以是其他服务器的地址，那么文件的存储容量就将是整个分布式服务器集群的硬盘容量，这样还可以在不同的服务器上同时并行读取文件的数据块，文件访问速度也将极大地加快。

这样的文件系统就是分布式文件系统，分布式文件系统的思路其实和 RAID 是一脉相承的，就是将数据分成很多片，同时向 N 台服务器上进行数据写入。针对一片数据丢失就导致整个文件损坏的情况，分布式文件系统也是采用数据备份的方式，将多个备份数据片写入多个服务器，以保证文件的可用性。当然，也可以采用 RAID 5 的方式通过计算校验数据片的方式提高文件可用性。

HDFS 的关键组件有两个，一个是 DataNode，一个是 NameNode。

DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分割成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分布存储在整个 HDFS 服务器集群中。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得 HDFS 可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。在实践中，HDFS 集群的 DataNode 服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块硬盘，整个集群的存储容量大概在几 PB 到数百 PB。

NameNode 负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、访问权限、数据块的 ID 以及存储位置等信息，相当于 Linux 系统中 inode 的角色。HDFS 为了保证数据的高可用，会将一个数据块复制为多份（缺省情况为 3 份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有硬盘损坏，或者某个 DataNode 服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。

有了 HDFS，可以实现单一文件存储几百 T 的数据，再配合大数据计算框架 MapReduce 或者 Spark，可以对这个文件的数据块进行并发计算。也可以使用 Impala 这样的 SQL 引擎对这个文件进行结构化查询，在数千台服务器上并发遍历 100T 的数据，1 分钟都是绰绰有余的。

总结

文件系统从简单操作系统文件，到 RAID，再到分布式文件系统，其设计思路其实是具有统一性的。这种统一性一方面体现在文件数据如何管理，也就是如何通过文件控制块管理文件的数据，这个文件控制块在 Linux 系统中就是 inode，在 HDFS 中就是 NameNode。

另一方面体现在如何利用更多的硬盘实现越来越大的文件存储需求和越来越快的读写速度需求，也就是将数据分片后同时写入多块硬盘。单服务器我们可以通过 RAID 来实现，多服务器则可以将这些服务器组成一个文件系统集群，共同对外提供文件服务，这时候，数千台服务器的数万块硬盘以单一存储资源的方式对文件使用者提供服务，也就是一个文件可以存储数百 T 的数据，并在一分钟完成这样一个大文件的遍历。

思考题

RAID5 中，校验位之所以螺旋式地落在所有硬盘上，主要原因是如果将校验位记录在同一块硬盘上，那么对于其他多块数据盘，任何一块硬盘修改数据都需要修改这个校验盘上的校验数据，也就是说，对于有 8 块硬盘的 RAID5 阵列，校验盘的数据写入压力是其他数据盘的 7 倍。而硬盘的频繁写入会导致硬盘寿命缩短，校验盘会频繁损坏，存储的整体可用性和维护性都会变差。

### 06 | 数据库原理：为什么 PreparedStatement 性能更好更安全？

SQL 执行过程

一个 SQL 提交到数据库，经过连接器将 SQL 语句交给语法分析器，生成一个抽象语法树 AST；AST 经过语义分析与优化器，进行语义优化，使计算过程和需要获取的中间数据尽可能少，然后得到数据库执行计划；执行计划提交给具体的执行引擎进行计算，将结果通过连接器再返回给应用程序。

使用 PreparedStatement 执行 SQL 的好处

一个是 PreparedStatement 会预先提交带占位符的 SQL 到数据库进行预处理，提前生成执行计划，当给定占位符参数真正执行 SQL 的时候，执行引擎可以直接执行，效率更好一点。

另一个好处则更为重要，PreparedStatement 可以防止 SQL 注入攻击。

因为一开始构造 PreparedStatement 的时候就已经提交了查询 SQL，并被数据库预先生成好了执行计划，后面黑客不管提交什么样的字符串，都只能交给这个执行计划去执行，不可能再生成一个新的 SQL 了，也就不会被攻击了。

### 07 | 编程语言原理：面向对象编程是编程的终极形态吗？

### 答疑 | Java Web 程序的运行时环境到底是怎样的？

首先，我们是通过执行 Tomcat 的 Shell 脚本启动 Tomcat 的，而在 Shell 脚本里，其实启动的是 Java 虚拟机，大概是这样一个 Shell 命令：

`java org.apache.catalina.startup.Bootstrap "$@" start`

所以我们在 Linux 操作系统执行 Tomcat 的 Shell 启动脚本，Tomcat 启动以后，其实在操作系统里看到的是一个 JVM 虚拟机进程。这个虚拟机进程启动以后，加载 class 进来执行，首先加载的就这个 org.apache.catalina.startup.Bootstrap 类，这个类里面有一个 main() 函数，是整个 Tomcat 的入口函数，JVM 虚拟机会启动一个主线程从这个入口函数开始执行。

主线程从 Bootstrap 的 main() 函数开始执行，初始化 Tomcat 的运行环境，这时候就需要创建一些线程，比如负责监听 80 端口的线程，处理客户端连接请求的线程，以及执行用户请求的线程。创建这些线程的代码是 Tomcat 代码的一部分。

初始化运行环境之后，Tomcat 就会扫描 Web 程序路径，扫描到开发的 war 包后，再加载 war 包里的类到 JVM。因为 Web 应用是被 Tomcat 加载运行的，所以我们也称 Tomcat 为 Web 容器。

如果有外部请求发送到 Tomcat，也就是外部程序通过 80 端口和 Tomcat 进行 HTTP 通信的时候，Tomcat 会根据 war 包中的 web.xml 配置，决定这个请求 URL 应该由哪个 Servlet 处理，然后 Tomcat 就会分配一个线程去处理这个请求，实际上，就是这个线程执行相应的 Servlet 代码。

如果 Tomcat 的线程在执行代码时抛出未处理的异常，那么当前线程就会结束执行，这时控制台看到的异常信息就是线程堆栈信息，线程会把异常信息以及当前堆栈的方法都打印出来。事实上，这个异常最后还是会被 Tomcat 捕获，然后 Tomcat 会给客户端返回一个 500 错误。单个线程的异常不影响其他线程执行，也就是不影响其他请求的处理。

但是如果线程在执行代码的时候抛出的是 JVM 错误，比如 OutOfMemoryError，这个时候看起来是应用 crash，事实上是整个进程都无法继续执行了，也就是进程 crash 了，进程内所有应用都不会被继续执行了。

### 08 | 软件设计的方法论：软件为什么要建模？

软件建模

通过建模，我们可以把握事物的本质规律和主要特征，正确建造模型和使用模型，以防在各种细节中迷失方向。软件系统庞大复杂，通过软件建模，我们可以抽象软件系统的主要特征和组成部分，梳理这些关键组成部分的关系，在软件开发过程中依照模型的约束开发，系统整体的格局和关系就会可控，相关人员从始至终都能清晰了解软件的蓝图和当前的进展，不同的开发工程师会很清晰自己开发的模块和其他同事工作内容的关系与依赖，并按照这些模型开发代码。

在软件开发中，有两个客观存在，一个是我们要解决的领域问题，对这些客观领域问题的抽象就是各种功能及其关系、各种模型对象及其关系、各种业务处理流程。

另一个客观存在就是最终开发出来的软件系统，这个软件系统也是客观存在的，软件由哪些主要类组成，这些类如何组织构成一个个的组件，这些类和组件之间的依赖关系如何，运行期如何调用，需要部署多少台服务器，服务器之间如何通信等。

![软件建模](https://github.com/songor/interview/blob/master/picture/%E8%BD%AF%E4%BB%B6%E5%BB%BA%E6%A8%A1.jpg)

所有这两个方面客观存在的抽象，就是我们的软件模型，一方面我们要对领域问题和软件系统进行分析、设计、抽象，另一方面，我们根据抽象出来的模型开发，实现出最终的软件系统。这就是软件开发的主要过程。而对领域问题和软件系统进行分析、设计和抽象的这个过程，我们专门划分出来，就是软件建模与设计。

4+1 视图模型

![4+1 视图模型](https://github.com/songor/interview/blob/master/picture/4%2B1%20%E8%A7%86%E5%9B%BE%E6%A8%A1%E5%9E%8B.jpg)

逻辑视图：描述软件的功能逻辑，由哪些模块组成，模块中包含哪些类，其依赖关系如何。

开发视图：包括系统架构层面的层次划分，包的管理，依赖的系统与第三方的程序包。开发视图某些方面和逻辑视图有一定重复性，不同视角看到的可能是同一个东西，开发视图中一个程序包，可能正好对应逻辑视图中的一个功能模块。

过程视图：描述程序运行期的进程、线程、对象实例，以及与此相关的并发、同步、通信等问题。

物理视图：描述软件如何安装并部署到物理的服务上，以及不同的服务器之间如何关联、通信。

场景视图：针对具体的用例场景，将上述 4 个视图关联起来，一方面从业务角度描述，功能流程如何完成，一方面从软件角度描述，相关组成部分如何互相依赖、调用。

### 09 | 软件设计实践：如何使用 UML 完成一个设计文档？

4+1 视图模型很好地向我们展示了如何对一个软件的不同方面用不同的模型图进行建模与设计，以完整描述一个软件的业务场景与技术实现。但是软件开发是有阶段性的，在不同的开发阶段用不同的模型图描述业务场景与设计思路，在不同阶段输出不同的设计文档，对于现实的开发更有实践意义。

软件建模与设计过程可以拆分成需求分析、概要设计和详细设计三个阶段。UML 规范包含了十多种模型图，常用的有 7 种：类图、序列图、组件图、部署图、用例图、状态图和活动图。

类图

类图是最常见的 UML 图形，用来描述类的特性和类之间的静态关系。

一个类包含三个部分：类的名字、类的属性列表和类的方法列表。类之间有 6 种静态关系：关联、依赖、组合、聚合、继承、泛化。把相关的一组类及其关系用一张图画出来，就是类图。

类图主要是在详细设计阶段画，如果类图已经设计出来了，那么开发工程师只需要按照类图实现代码就可以了，只要类方法的逻辑不是太复杂，不同的工程师实现出来的代码几乎是一样的，这样可以保证软件的规范、统一。在实践中，我们通常不需要把一个软件所有的类都画出来，把核心的、有代表性的、有一定技术难度的类图画出来，一般就可以了。

除了在详细设计阶段画类图，在需求分析阶段，也可以将关键的领域模型对象用类图画出来，在这个阶段中，我们需要关注的是领域对象的识别及其关系，所以用简化的类图来描述，只画出类的名字及关系就可以了。

序列图

序列图通常用于表示对象之间的交互，这个对象可以是类对象，也可以是更大粒度的参与者，比如组件、服务器、子系统等，总之，只要是描述不同参与者之间交互的，都可以使用序列图，也就是说，在软件设计的不同阶段，都可以画序列图。

组件图

组件是比类粒度更大的设计元素，一个组件中通常包含很多个类。组件图有的时候和包图的用途比较接近，组件图通常用来描述物理上的组件，比如一个 JAR，一个 DLL 等等。在实践中，我们进行模块设计的时候更多的是用组件图。

组件图描述组件之间的静态关系，主要是依赖关系，如果想要描述组件之间的动态调用关系，可以使用组件序列图，以组件作为参与者，描述组件之间的消息调用关系。

因为组件的粒度比较粗，通常用以描述和设计软件的模块及其之间的关系，需要在设计早期阶段就画出来，因此组件图一般用在概要设计阶段。

部署图

部署图描述软件系统的最终部署情况，比如需要部署多少服务器，关键组件都部署在哪些服务器上。

部署图是软件系统最终物理呈现的蓝图，根据部署图，所有相关者，诸如客户、老板、工程师都能清晰地了解到最终运行的系统在物理上是什么样子，和现有的系统服务器的关系，和第三方服务器的关系。根据部署图，还可以估算服务器和第三方软件的采购成本。

因此部署图是整个软件设计模型中，比较宏观的一种图，是在设计早期就需要画的一种模型图。根据部署图，各方可以讨论对这个方案是否认可。只有对部署图达成共识，才能继续后面的细节设计。部署图主要用在概要设计阶段。

用例图

用例图主要用在需求分析阶段，通过反映用户和软件系统的交互，描述系统的功能需求。

状态图

状态图用来展示单个对象生命周期的状态变迁。

状态图要在需求分析阶段画，描述状态变迁的逻辑关系，在详细设计阶段也要画，这个时候，状态要用枚举值表示，以指导具体的开发。

活动图

活动图主要用来描述过程逻辑和业务流程。UML 中没有流程图，很多时候，人们用活动图代替流程图。

活动图可以根据活动的范围，将活动根据领域、系统和角色等划分到不同的泳道中，使流程边界更加清晰。

活动图也比较有普适性，可以在需求分析阶段描述业务流程，也可以在概要设计阶段描述子系统和组件的交互，还可以在详细设计阶段描述一个类方法内部的计算流程。

使用合适的 UML 模型构建一个设计文档

在需求分析阶段，主要是通过用例图来描述系统的功能与使用场景；对于关键的业务流程，可以通过活动图描述；如果在需求阶段就提出要和现有的某些子系统整合，那么可以通过时序图描述新系统和原来的子系统的调用关系；可以通过简化的类图进行领域模型抽象，并描述核心领域对象之间的关系；如果某些对象内部会有复杂的状态变化，比如用户、订单这些，可以用状态图进行描述。

在概要设计阶段，通过部署图描述系统最终的物理蓝图；通过组件图以及组件时序图设计软件主要模块及其关系；还可以通过组件活动图描述组件间的流程逻辑。

在详细设计阶段，主要输出的就是类图和类的时序图，指导最终的代码开发，如果某个类方法内部有比较复杂的逻辑，那么可以用画方法的活动图进行描述。

### 10 | 软件设计的目的：糟糕的程序员比优秀的程序员差在哪里？

程序员的好坏，一方面体现在编程能力上；另一方面，体现在程序设计方面。

在软件设计开发这个领域，好的设计和坏的设计最大的差别就体现在应对需求变更的能力上。

糟糕的设计

僵化性：软件代码之间耦合严重，难以改动，任何微小的改动都会引起更大范围的改动。

脆弱性：比僵化性更糟糕的是脆弱性，僵化导致任何一个微小的改动都能引起更大范围的改动，而脆弱则是微小的改动容易引起莫名其妙的崩溃或者 bug，出现 bug 的地方看似与改动的地方毫无关联，或者软件进行了一个看似简单的改动，重新启动，然后就莫名其妙地崩溃了。

牢固性：牢固性是指软件无法进行快速、有效地拆分。想要复用软件的一部分功能，却无法容易地将这部分功能从其他部分中分离出来。

粘滞性：需求变更导致软件变更的时候，如果糟糕的代码变更方案比优秀的方案更容易实施，那么软件就会向糟糕的方向发展。

晦涩性：代码首先是给人看的，其次是给计算机执行的。如果代码晦涩难懂，必然会导致代码的维护者以设计者不期望的方式对代码进行修改，导致系统腐坏变质。

应对需求变更最好的办法就是一开始的设计就是针对需求变更的，并在开发过程中根据真实的需求变更不断重构代码，保持代码对需求变更的灵活性。

我们在开始设计的时候就需要考虑程序如何应对需求变更，并因此指导自己进行软件设计，在开发过程中，需要敏锐地察觉到哪些地方正在变得腐坏，然后用设计原则去判断问题是什么，再用设计模式去重构代码解决问题。

### 11 | 软件设计的开闭原则：如何不修改代码却能实现需求变更？

软件实体（模块、类、函数等等）应该对扩展是开放的，对修改是关闭的。

对扩展是开放的，意味着软件实体的行为是可扩展的，当需求变更的时候，可以对模块进行扩展，使其满足需求变更的要求。

对修改是关闭的，意味着当对软件实体进行扩展的时候，不需要改动当前的软件实体；不需要修改代码；对于已经完成的类文件不需要重新编辑；对于已经编译打包好的模块不需要重新编译。

通俗的说就是，软件功能可以扩展，但是软件实体不可以被修改。

粗暴一点说，当我们在代码中看到 if/else 或者 switch/case 关键字的时候，基本可以判断违反开闭原则了。

策略模式是一种行为模式，多个策略实现同一个策略接口，编程的时候 client 程序依赖策略接口，运行期根据不同上下文向 client 程序传入不同的策略实现。

适配器模式是一种结构模式，用于将两个不匹配的接口适配起来，使其能够正常工作。

观察者模式是一种行为模式，解决一对多的对象依赖关系，将被观察者对象的行为通知到多个观察者，也就是监听者对象。

模板方法模式，就是在父类中用抽象方法定义计算的骨架和过程，而抽象方法的实现则留在子类中。

实现开闭原则的关键是抽象。当一个模块依赖的是一个抽象接口的时候，就可以随意对这个抽象接口进行扩展，这个时候，不需要对现有代码进行任何修改，利用接口的多态性，通过增加一个新实现该接口的实现类，就能完成需求变更。不同场景进行扩展的方式是不同的，这时候就会产生不同的设计模式，大部分的设计模式都是用来解决扩展的灵活性问题的。

开闭原则可以说是软件设计原则的原则，是软件设计的核心原则，其他的设计原则更偏向技术性，具有技术性的指导意义，而开闭原则是方向性的，在软件设计的过程中，应该时刻以开闭原则指导、审视自己的设计：当需求变更的时候，现在的设计能否不修改代码就可以实现功能的扩展？如果不是，那么就应该进一步使用其他的设计原则和设计模式去重新设计。

### 12 | 软件设计的依赖倒置原则：如何不依赖代码却可以复用它的功能？

框架的一个特点是，当开发者使用框架开发一个应用程序时，无需在程序中调用框架的代码，就可以使用框架的功能特性。

依赖倒置原则是这样的：高层模块不应该依赖低层模块，二者都应该依赖抽象；抽象不应该依赖具体实现，具体实现应该依赖抽象。

软件分层设计已经是软件开发者的共识。事实上，最早引入软件分层设计，正是为了建立清晰的软件分层关系，便于高层模块依赖低层模块。一般的应用程序中，策略层会依赖方法层，业务逻辑层会依赖数据存储层。

那么这种高层模块依赖低层模块的分层依赖方式有什么缺点呢？

一是维护困难，高层模块通常是业务逻辑和策略模型，是一个软件的核心所在。正是高层模块使一个软件区别于其他软件，而低层模块则更多的是技术细节。如果高层模块依赖低层模块，那么就是业务逻辑依赖技术细节，技术细节的改变将影响到业务逻辑，使业务逻辑也不得不做出改变。因为技术细节的改变而影响业务代码的改变，这是不合理的。

二是复用困难，通常越是高层模块，复用的价值越高。但如果高层模块依赖低层模块，那么对高层模块的依赖将会导致对底层模块的连带依赖，使复用变得困难。

依赖倒置的关键是接口所有权的倒置

![传递依赖](https://github.com/songor/interview/blob/master/picture/%E4%BC%A0%E9%80%92%E4%BE%9D%E8%B5%96.jpg)

这样分层依赖的一个潜在问题是，策略层对方法层和工具层是传递依赖的，下面两层的任何改动都会导致策略层的改动，这种传递依赖导致的级联改动可能会导致软件维护过程非常糟糕。

解决办法是利用依赖倒置的设计原则，每个高层模块都为它所需要的服务声明一个抽象接口，而低层模块则实现这些抽象接口，高层模块通过抽象接口使用低层模块。

![使用依赖倒置原则解决传递依赖](https://github.com/songor/interview/blob/master/picture/%E4%BD%BF%E7%94%A8%E4%BE%9D%E8%B5%96%E5%80%92%E7%BD%AE%E5%8E%9F%E5%88%99%E8%A7%A3%E5%86%B3%E4%BC%A0%E9%80%92%E4%BE%9D%E8%B5%96.jpg)

这样，高层模块就不需要直接依赖低层模块，而变成了低层模块依赖高层模块定义的抽象接口，从而实现了依赖倒置，解决了策略层、方法层、工具层的传递依赖问题。

依赖倒置原则中，除了具体实现要依赖抽象，最重要的是，抽象是属于谁的抽象。

通常的编程习惯中，低层模块拥有自己的接口，高层模块依赖低层模块提供的接口。但是按照依赖倒置原则，接口的所有权是被倒置的，也就是说，接口被高层模块定义，高层模块拥有接口，低层模块实现接口。不是高层模块依赖低层模块的接口，而是低层模块依赖高层模块的接口，从而实现依赖关系的倒置。

使用依赖倒置实现高层模块复用

Tomcat、Spring 都是基于这一原则设计出来的，应用程序不需要调用 Tomcat 或者 Spring 这样的框架，而是框架调用应用程序。而实现这一特性的前提就是应用程序必须实现框架的接口规范，比如实现 Servlet 接口。

遵循依赖倒置原则有这样几个编码守则：

应用代码中多使用抽象接口，尽量避免使用那些多变的具体实现类。

不要继承具体类，如果一个类在设计之初不是抽象类，那么尽量不要去继承它。对具体类的继承是一种强依赖关系，维护的时候难以改变。

不要重写（override）包含具体实现的函数。

依赖倒置原则最典型的使用场景就是框架的设计。框架提供框架核心功能，比如 HTTP 处理，MVC 等，并提供一组接口规范，应用程序只需要遵循接口规范编程，就可以被框架调用。程序使用框架的功能，但是不调用框架的代码，而是实现框架的接口被框架调用，从而框架有更高的可复用性，被应用于各种软件开发中。

### 13 | 软件设计的里氏替换原则：正方形可以继承长方形吗？

我们都知道，面向对象编程语言有三大特性：封装、继承、多态。

通俗地说，接口（抽象类）的多个实现就是多态。多态可以让程序在编程时面向接口进行编程，在运行期绑定具体类，从而使得类之间不需要直接耦合，就可以关联组合，构成一个更强大的整体对外服务。

封装是面向对象语言提供的特性，将属性和方法封装在类里面。用好封装的关键是，知道应该将哪些属性和方法封装在某个类里。

里氏替换原则

子类型必须能够替换掉它们的基类型。

程序中，所有使用基类的地方，都应该可以用子类代替。

通常，我们判断一个继承是否合理，会使用“IS A”进行判断，类 B 可以继承类 A，我们就说类 B IS A 类 A，比如白马 IS A 马，轿车 IS A 车。

继承是否合理我们需要用里氏替换原则来判断。是否合理并不是从继承的设计本身看，而是从应用场景的角度看。如果在应用场景中，也就是在程序中，子类可以替换父类，那么继承就是合理的，如果不能替换，那么继承就是不合理的。

子类不能比父类更严格

类的公有方法其实是对使用者的一个契约，使用者按照这个契约使用类，并期望类按照契约运行，返回合理的值。

当子类继承父类的时候，根据里氏替换原则，使用者可以在使用父类的地方使用子类替换，那么从契约的角度，子类的契约就不能比父类更严格，否则使用者在用子类替换父类的时候，就会因为更严格的契约而失败。

正方形继承了长方形，但是正方形有比长方形更严格的契约，即正方形要求长和宽是一样的。因为正方形有比长方形更严格的契约，那么在使用长方形的地方，正方形因为更严格的契约而无法替换长方形。

在类的继承中，如果父类方法的访问控制是 protected，那么子类 override 这个方法的时候，可以改成是 public，但是不能改成 private。因为 private 的访问控制比 protected 更严格，能使用父类 protected 方法的地方，不能用子类的 private 方法替换，否则就是违反里氏替换原则的。相反，如果子类方法的访问控制改成 public 就没问题，即子类可以有比父类更宽松的契约。

一个类如果不是为了被继承而设计，那么最好就不要继承它。粗暴一点地说，如果不是抽象类或者接口，最好不要继承它。

如果你确实需要使用一个类的方法，最好的办法是组合这个类而不是继承这个类，这就是人们通常说的组合优于继承。

### 14 | 软件设计的单一职责原则：为什么说一个类文件打开最好不要超过一屏？

单一职责原则

软件设计有两个基本准则：低耦合和高内聚。

我在前面讲到过的设计原则和后面将要讲的设计模式大多数都是关于如何进行低耦合设计的。

而内聚性主要研究组成一个模块或者类的内部元素的功能相关性。设计类的时候，我们应该把强相关的元素放在一个类里，而弱相关性的元素放在类的外边，保持类的高内聚性。具体设计时应该遵循这样一个设计原则：一个类，应该只有一个引起它变化的原因。

如果一个类承担的职责太多，就等于把这些职责都耦合在一起，这种耦合会导致类很脆弱：当变化发生的时候，会引起类不必要的修改，进而导致 bug 出现。

职责太多，还会导致类的代码太多。一个类太大，它就很难保证满足开闭原则，如果不得不打开类文件进行修改，大堆大堆的代码呈现在屏幕上，一不小心就会引出不必要的错误。

所以关于编程有这样一个最佳实践：一个类文件打开后，最好不要超过屏幕的一屏。这样做的好处是：一方面代码少，职责单一，可以更容易地进行复用和扩展，更符合开闭原则；另一方面，阅读简单，维护方便。

从 Web 应用架构演进看单一职责原则

真正将视图和模型分离的是后来出现的各种 MVC 框架，MVC 框架通过控制器将视图与模型彻底分离。视图中只包含 HTML 标签和模板引擎的占位符，业务模型则专门负责进行业务处理。正是这种分离，使得前后端开发成为两个不同的工种，前端工程师只做视图模板开发，后端工程师只做业务开发，彼此之间没有直接的依赖和耦合，各自独立开发、维护自己的代码。

有了 MVC，就可以顺理成章地将复杂的业务模型进行分层了。通过分层方式，将业务模型分为业务层、服务层、数据持久层，使各层职责进一步分离，更符合单一职责原则。

### 15 | 软件设计的接口隔离原则：如何对类的调用者隐藏类的公有方法？

接口隔离原则

接口隔离原则说：不应该强迫用户依赖他们不需要的方法。

那么如果强迫用户依赖他们不需要的方法，会导致什么后果呢？

一来，用户可以看到这些他们不需要也不理解的方法，这样无疑会增加他们使用的难度，如果错误地调用了这些方法，就会产生 bug；二来，当这些方法因为某种原因需要更改的时候，虽然不需要但是依赖这些方法的用户程序也必须做出更改，这是一种不必要的耦合。

![Modem 接口隔离原则](https://github.com/songor/interview/blob/master/picture/Modem%20%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99.jpg)

通过使用接口隔离原则，我们可以将一个实现类的不同方法包装在不同的接口中对外暴露。应用程序只需要依赖它们需要的方法，而不会看到不需要的方法。

一个使用接口隔离原则优化的例子

```java
class Door {
    void lock();
    void unlock();
    boolean isDoorOpen();
}

class Timer {
    void register(int timeout, TimerClient client);
}

interface TimerClient {
    void timeout();
}
```

TimerClient 可以向 Timer 注册，调用 register() 方法设置超时时间，当超时时间到，就会调用 TimerClient 的 timeout() 方法。

```java
class Door implements TimerClient {
    void lock();
    void unlock();
    boolean isDoorOpen();
    void timeout(){
      lock();
    }
}
```

如果这个 Door 类想要复用到其他地方，那么所有使用 Door 的程序都不得不依赖一个它们可能根本用不着的 timeout() 方法。同时，Door 的职责也变得复杂，违反了单一职责原则，维护会变得更加困难。

一种方法是通过委托进行接口隔离：

![通过委托进行接口隔离](https://github.com/songor/interview/blob/master/picture/%E9%80%9A%E8%BF%87%E5%A7%94%E6%89%98%E8%BF%9B%E8%A1%8C%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB.jpg)

如果超时的时候需要执行较多的逻辑操作，那么适配器的 timeout() 方法就会包含很多业务逻辑，超出了适配器的职责范围。

接口隔离更典型的做法是使用多重继承：

![使用多重继承进行接口隔离](https://github.com/songor/interview/blob/master/picture/%E4%BD%BF%E7%94%A8%E5%A4%9A%E9%87%8D%E7%BB%A7%E6%89%BF%E8%BF%9B%E8%A1%8C%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB.jpg)

这样，使用 Door 的程序就不需要被迫依赖 timeout() 方法，Timer 也不会看到 Door 的方法，程序更加整洁，易于复用。

### 16 | 设计模式基础：不会灵活应用设计模式，你就没有掌握面向对象编程

设计模式的精髓在于对面向对象编程特性之一——多态的灵活应用，而多态正是面向对象编程的本质所在。

在面向对象的编程语言中，多态非常简单：子类实现父类或者接口的抽象方法，程序使用抽象父类或者接口编程，运行期注入不同的子类，程序就表现出不同的形态，是为多态。

这样做最大的好处就是软件编程时的实现无关性，程序针对接口和抽象类编程，而不需要关心具体实现是什么。

通过使用接口，我们定义了 Reader 和 Writer 两个接口，分别描述输入设备和输出设备，拷贝程序只需要针对这两个接口编程，而无需关心具体设备是什么，程序可以保持稳定，并且易于复用。具体设备在程序运行期创建，然后传给拷贝程序，传入什么具体设备，就在什么具体设备上操作拷贝逻辑，具体设备可以像插件一样，灵活插拔，使程序呈现多态的特性。

多态还颠覆了程序模块间的依赖关系。在习惯的编程思维中，如果 A 模块调用 B 模块，那么 A 模块必须依赖 B 模块，也就是说，在 A 模块的代码中必须 import 或者 using B 模块的代码。但是通过使用多态的特性，我们可以将这个依赖关系倒置，也就是：A 模块调用 B 模块，A 模块却可以不依赖 B 模块，反而是 B 模块依赖 A 模块。

准确地说，B 模块也没有依赖 A 模块，而是依赖 A 模块定义的抽象接口。A 模块针对抽象接口编程，调用抽象接口，B 模块实现抽象接口。在程序运行期将 B 模块注入 A 模块，就使得 A 模块调用 B 模块，却没有依赖 B 模块。

设计原则

开闭原则：软件类、模块应该是对修改关闭的，而对扩展是开放的。通俗地说，就是要不修改代码就实现需求的变更。

依赖倒置原则：高层模块不应该依赖低层模块，低层模块也不应该依赖高层模块，他们应该都依赖抽象，而这个抽象是高层定义的，逻辑上属于高层。

里氏替换原则：所有能够使用父类的地方，应该都可以用它的子类替换。但要注意的是，能不能替换是要看应用场景的，所以在设计继承的时候就要考虑运行期的场景，而不是仅仅考虑父类和子类的静态关系。

单一职责原则：一个类应该只有一个引起它变化的原因。实践中，就是类文件尽量不要太大，最好不要超过一屏。

接口隔离原则：不要强迫调用者依赖他们不需要的方法。通过对接口的多重继承，一个类实现多个接口，不同接口服务不同调用者，不同调用者看到不同方法。

设计模式

模式是可重复的解决方案，人们在编程实践中发现有些问题是重复出现的，虽然场景各有不同，但是问题的本质是一样的，而解决这些问题的方法也是可以重复使用的。

多态的迷人之处就在于，你单独看类的代码的时候，这些代码似乎平淡无奇，但是一旦运行起来，就会表现出纷繁复杂的特性。

如果你只是使用面向对象编程语言进行编程，其实并不能说明你就掌握了面向对象编程。只有灵活应用设计模式，使程序呈现多态的特性，进而使程序健壮、灵活、清晰、易于维护和复用，这才是真正掌握了面向对象编程。

### 17 | 设计模式应用：编程框架中的设计模式

什么是框架

框架是对某一类架构方案可复用的设计与实现。

但并不是所有可被复用的组件都被称作框架，框架通常规定了一个软件的主体结构，可以支撑起软件的整体或者局部的架构形式。比如说，Tomcat 完成了 Web 应用请求响应的主体流程，我们只需要开发 Servlet 完成请求处理逻辑，构造响应对象就可以了，所以 Tomcat 是一个框架。

还有一类可复用的组件不控制软件的主体流程，也不支撑软件的整体架构，比如 Log4J 提供了一个可复用的日志输出功能，但是，日志输出功能不是软件的主体结构，所以我们通常不称 Log4J 为框架，而称其为工具。

一般说来，我们使用框架编程的时候，需要遵循框架的规范编写代码。这些框架会调用我们编写的代码，而我们编写的代码则会调用工具完成某些特定的功能。

Web 容器中的设计模式

Web 容器主要使用了策略模式，多个策略实现同一个策略接口。编程的时候 Tomcat 依赖策略接口，而在运行期根据不同上下文，Tomcat 装载不同的策略实现。

这里的策略接口就是 Servlet 接口，而我们开发的代码就是实现这个 Servlet 接口处理 HTTP 请求。

Web 容器完成了 HTTP 请求处理的主要流程，指定了 Servlet 接口规范，实现了 Web 开发的主要架构，开发者只要在这个架构下开发具体 Servlet 就可以了。因此我们可以称 Tomcat、Jetty 这类 Web 容器为框架。

HttpServlet 还用到了模板方法模式，所谓模板方法模式，就是在父类中用抽象方法定义计算的骨架和过程，而抽象方法的实现则留在子类中。

JUnit 中的设计模式

JUnit 在这里也使用了模板方法模式，测试用例的方法执行顺序被固定在 JUnit 框架的模板方法里。

```java
public void runBare() throws Throwable {
    setUp();
    try {
        runTest();
    } finally {
        tearDown();
    }
}
```

JUnit 提供了一个测试套件 TestSuit 管理、组织测试用例。

![TestSuite 是一个树状结构](https://github.com/songor/interview/blob/master/picture/TestSuite%20%E6%98%AF%E4%B8%80%E4%B8%AA%E6%A0%91%E7%8A%B6%E7%BB%93%E6%9E%84.jpg)

当我们从树的根节点遍历树，就可以执行所有这些测试用例。传统上进行树的遍历需要递归编程的，而使用组合模式无需递归也可以遍历树。

### 18 | 反应式编程框架设计：如何使程序调用不阻塞等待，立即响应？

反应式编程

反应式编程本质上是一种异步编程方案，在多线程（协程）、异步方法调用、异步 I/O 访问等技术基础之上，提供了一整套与异步调用相匹配的编程模型，从而实现程序调用非阻塞、即时响应等特性，即开发出一个反应式的系统，以应对编程领域越来越高的并发处理需求。

反应式宣言：

即时响应，应用的调用者可以即时得到响应，无需等到整个应用程序执行完毕。也就是说应用调用是非阻塞的。

回弹性，当应用程序部分功能失效的时候，应用系统本身能够进行自我修复，保证正常运行，保证响应，不会出现系统崩溃和宕机的情况。

弹性，系统能够对应用负载压力做出响应，能够自动伸缩以适应应用负载压力，根据压力自动调整自身的处理能力，或者根据自身的处理能力，调整进入系统中的访问请求数量。

消息驱动，功能模块之间，服务之间，通过消息进行驱动，完成服务的流程。

目前主流的反应式编程框架有 RxJava、Reactor 等，它们的主要特点是基于观察者设计模式的异步编程方案，编程模型采用函数式编程。

反应式编程框架 Flower 的基本原理

![Flower 基本原理](https://github.com/songor/interview/blob/master/picture/Flower%20%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.jpg)

当并发用户到达应用服务器的时候，Web 容器线程不需要执行应用程序代码，它只是将用户的 HTTP 请求变为请求对象，将请求对象异步交给 Flower 框架的 Service 去处理，自身立刻就返回。因为容器线程不做太多的工作，所以只需极少的容器线程就可以满足高并发的用户请求，用户的请求不会被阻塞，不会因为容器线程不够而无法处理。相比传统的阻塞式编程，Web 容器线程要完成全部的请求处理操作，直到返回响应结果才能释放线程；使用 Flower 框架只需要极少的容器线程就可以处理较多的并发用户请求，而且容器线程不会阻塞。

用户请求交给基于 Flower 框架开发的业务 Service 对象以后，Service 之间依然是使用异步消息通讯的方式进行调用，不会直接进行阻塞式的调用。一个 Service 完成业务逻辑处理计算以后，会返回一个处理结果，这个结果以消息的方式异步发送给它的下一个 Service。

传统编程模型的 Service 之间如果进行调用，被调用的 Service 在返回之前，调用的 Service 方法只能阻塞等待。而 Flower 的 Service 之间使用了 AKKA Actor 进行消息通信，调用者的 Service 发送调用消息后，不需要等待被调用者返回结果，就可以处理自己的下一个消息了。事实上，这些 Service 可以复用同一个线程去处理自己的消息，也就是说，只需要有限的几个线程就可以完成大量的 Service 处理和消息传输，这些线程不会阻塞等待。

Flower 支持异步数据库驱动，用户请求数据库的时候，将请求提交给异步数据库驱动后就立刻返回，不会阻塞当前线程，异步数据库访问远程的数据库进行真正的数据库操作，得到结果以后，将结果以异步回调的方式发送给 Flower 的 Service 进行进一步的处理，这个时候依然不会有线程被阻塞。

也就是说，使用 Flower 开发的系统，在一个典型的 Web 应用中，几乎没有任何地方会被阻塞，所有的线程都可以被不断地复用，有限的线程就可以完成大量的并发用户请求，从而大大地提高了系统的吞吐能力和响应时间，同时，由于线程不会被阻塞，应用就不会因为并发量太大或者数据库处理缓慢而宕机，从而提高了系统的可用性。

Flower 框架实现异步无阻塞，一方面是利用了 Web 容器的异步特性，主要是 Servlet3.0 以后提供的 AsyncContext，快速释放容器线程；另一方面是利用了异步的数据库驱动以及异步的网络通信，主要是 HttpAsyncClient 等异步通信组件。而 Flower 框架内，核心的应用代码之间的异步无阻塞调用，则是利用了 Akka 的 Actor 模型实现。

Akka Actor 的异步消息驱动实现如下：

![Akka Actor 异步消息驱动](https://github.com/songor/interview/blob/master/picture/Akka%20Actor%20%E5%BC%82%E6%AD%A5%E6%B6%88%E6%81%AF%E9%A9%B1%E5%8A%A8.jpg)

一个 Actor 向另一个 Actor 进行通讯的时候，当前 Actor 就是一个消息的发送者 Sender，当它想要向另一个 Actor 进行通讯的时候，就需要获得另一个 Actor 的 ActorRef，也就是一个引用，通过引用进行消息通信。而 ActorRef 收到消息以后，会将这个消息放入到目标 Actor 的 Mailbox 里面去，然后就立即返回了。

也就是说一个 Actor 向另一个 Actor 发送消息的时候，不需要另一个 Actor 去真正地处理这个消息，只需要将消息发送到目标 Actor 的 Mailbox 里面就可以了，自己不会被阻塞，可以继续执行自己的操作。而目标 Actor 检查自己的 Mailbox 中是否有消息，如果有消息，Actor 则会再从 Mailbox 里面去获取消息，对消息进行异步的处理。而所有的 Actor 会共享线程，这些线程不会有任何的阻塞。

反应式编程框架 Flower 的设计方法

![Actor 与 Service 的依赖倒置关系](https://github.com/songor/interview/blob/master/picture/Actor%20%E4%B8%8E%20Service%20%E7%9A%84%E4%BE%9D%E8%B5%96%E5%80%92%E7%BD%AE%E5%85%B3%E7%B3%BB.jpg)

Flower 框架的设计也是基于依赖倒置原则。所有应用开发者实现的 Service 类都需要包装在 Actor 里面进行异步调用，但是 Actor 不会依赖开发者实现的 Service 类，开发者也不会依赖 Actor 类，他们共同依赖一个 Service 接口，这个接口是框架提供的。

每个 Actor 都依赖一个 Service 接口，而具体的 Service 实现类（MyService）则实现这个 Service 接口，在运行期实例化 Actor 的时候，这个接口被注入具体的 Service 实现类。在 Flower 中，调用 MyService 对象，其实就是给包装 MyService 对象的 Actor 发消息，Actor 收到消息，执行自己的 onReceive 方法，在这个方法里，Actor 调用 MyService 的 process 方法，并将 onReceive 收到的 Message 对象当做 process 的输入参数传入。process 处理完成后，返回一个 Object 对象。Actor 会根据编排好的流程，获取 MyService 在流程中的下一个 Service 对应的 Actor，即 nextServiceActor，将 process 返回的 Object 对象当做消息发送给这个 nextServiceActor。这样，Service 之间就根据编排好的流程，异步、无阻塞地调用执行起来了。

### 19 | 组件设计原则：组件的边界在哪里？

软件开发这个行业很久之前就形成了一个共识，应该将复杂的软件系统进行拆分，拆成多个更低复杂度的子系统，子系统还可以继续拆分成更小粒度的组件。也就是说，软件需要进行模块化、组件化设计。

组件内聚原则

组件内聚原则主要讨论哪些类应该聚合在同一个组件中，以便组件既能提供相对完整的功能，又不至于太过庞大。

复用发布等同原则是说，软件复用的最小粒度应该等同于其发布的最小粒度。也就是说，如果你希望别人以怎样的粒度复用你的软件，你就应该以怎样的粒度发布你的软件。这其实就是组件的定义了，组件是软件复用和发布的最小粒度软件单元。

共同封闭原则是说，我们应该将那些会同时修改，并且为了相同目的而修改的类放到同一个组件中。而将不会同时修改，并且不会为了相同目的而修改的类放到不同的组件中。

也许将某些类放入这个组件中对于复用是便利的、合理的，但如果组件的复用与维护发生冲突，比如这些类将来的变更和整个组件将来的变更是不同步的，不会由于相同的原因发生变更，那么为了可维护性，应该谨慎考虑，是不是应该将这些类和组件放在一起。

共同复用原则是说，不要强迫一个组件的用户依赖他们不需要的东西。

组件耦合原则

组件耦合原则讨论组件之间的耦合关系应该如何设计。

无循环依赖原则说，组件依赖关系中不应该出现环。如果组件 A 依赖组件 B，组件 B 依赖组件 C，组件 C 又依赖组件 A，就形成了循环依赖。

稳定依赖原则说，组件依赖关系必须指向更稳定的方向。很少有变更的组件是稳定的，也就是说，经常变更的组件是不稳定的。根据稳定依赖原则，不稳定的组件应该依赖稳定的组件，而不是反过来。

反过来说，如果一个组件被更多组件依赖，那么它需要相对是稳定的，因为想要变更一个被很多组件依赖的组件，本身就是一件困难的事。相对应的，如果一个组件依赖了很多的组件，那么它相对也是不稳定的，因为它依赖的任何组件变更，都可能导致自己的变更。

稳定抽象原则说，一个组件的抽象化程度应该与其稳定性程度一致。也就是说，一个稳定的组件应该是抽象的，而不稳定的组件应该是具体的。

这个原则对具体开发的指导意义就是：如果你设计的组件是具体的、不稳定的，那么可以为这个组件对外提供服务的类设计一组接口，并把这组接口封装在一个专门的组件中，那么这个组件相对就比较抽象、稳定。

### 20 | 领域驱动设计：35 岁的程序员应该写什么样的代码？

领域模型模式

如果你对自己要开发的业务领域没有清晰的定义和边界，没有设计系统的领域模型，而仅仅跟着所谓的需求不断开发功能，一旦需求来自多个方面，就可能发生需求冲突，或者随着时间的推移，前后功能也会发生冲突，这时你越是试图弥补这些冲突，就越是陷入更大的冲突之中。

目前企业级应用开发中，业务逻辑的组织方式主要是事务脚本模式。事务脚本按照业务处理的过程组织业务逻辑，每个过程处理来自客户端的单个请求。客户端的每次请求都包含了一定的业务处理逻辑，而程序则按照每次请求的业务逻辑进行划分。

事务脚本模式典型的就是 Controller -> Service -> Dao 这样的程序设计模式。Controller 封装用户请求，根据请求参数构造一些数据对象调用 Service，Service 里面包含大量的业务逻辑代码，完成对数据的处理，期间可能需要通过 Dao 从数据库中获取数据，或者将数据写入数据库中。

在这里，Service 只是 * 的一个类，并没有什么设计的约束。

由于事务脚本模式中，Service、Dao 这些对象只有方法，没有数值成员变量，而方法调用时传递的数值对象没有方法（或者只有一些 getter、setter 方法），因此事务脚本又被称作贫血模型。

在领域模型模式下，业务逻辑围绕领域模型设计。

领域模型中的对象和事务脚本中的对象有很大的不同，比如事务脚本中也有合同 Contract 这个对象，但是这个 Contract 只包含合同的数据信息，不包含和合同有关的计算逻辑，计算逻辑在 Service 类里。

而领域模型的对象则包含了对象的数据和计算逻辑，比如合同对象，既包含合同数据，也包含合同相关的计算。因此从面向对象的角度看，领域模型才是真正的面向对象。

领域模型是合并了行为和数据的领域的对象模型，通过领域模型对象的交互完成业务逻辑的实现，也就是说，设计好了领域模型对象，也就设计好了业务逻辑实现。和事务脚本被称作贫血模型相对应的，领域模型也被称为充血模型。

对于复杂的业务逻辑实现来说，用领域模型模式更有优势。特别是在持续的需求变更和业务迭代过程中，把握好领域模型，对业务逻辑本身也会有更清晰的认识。

领域驱动设计（DDD）

领域是一个组织所做的事情以及其包含的一切，通俗地说，就是组织的业务范围和做事方式，也是软件开发的目标范围。

领域驱动设计就是从领域出发，分析领域内模型及其关系，进而设计软件系统的方法。

通常的做法是把整个领域拆分成多个子域，强相关的多个子域组成一个界限上下文，界限上下文是对业务领域范围的描述，对于系统实现而言，可以想象成相当于是一个子系统或者是一个模块，界限上下文和子域共同组成组织的领域。

不同的界限上下文，也就是不同的子系统或者模块之间会有各种的交互合作，DDD 使用上下文映射图来完成。

在 DDD 中，领域模型对象也被称为实体，每个实体都是唯一的，具有一个唯一标识，实体可能会发生变化，但是它们的唯一标识不会变化。

实体设计是 DDD 的核心所在，首先通过业务分析，识别出实体对象，然后通过相关的业务逻辑设计实体的属性和方法。这里最重要的，是要把握住实体的特征是什么，实体应该承担什么职责，不应该承担什么职责，分析的时候要放在业务场景和界限上下文中，而不是想当然地认为这样的实体就应该承担这样的角色。

事实上，并不是领域内的对象都应该被设计为实体，DDD 推荐尽可能将对象设计为值对象。

值对象的一个特点是不变性，一个值对象创建以后就不能再改变了。

领域实体和界限上下文包含了业务的主要逻辑，但是最终如何构建一个系统，如何将领域实体对外暴露，开发出一个完整的系统？事实上，DDD 支持各种架构方案，比如典型的分层架构：领域实体被放置在领域层，通过应用层对领域实体进行包装，最终提供一组访问接口，通过接口层对外开放。

六边形架构是 DDD 中比较知名的一种架构方式，领域模型通过应用程序封装成一个相对比较独立的模块，而不同的外部系统则通过不同的适配器和领域模型交互。

通过领域实体及其交互完成业务逻辑处理才是 DDD 的核心目标。

### 答疑 | 对于设计模式而言，场景到底有多重要？

如果你为需求变更而进行了设计，但是预期中的需求变更却从来没有发生过，那么你的设计就属于设计过度；如果已经发生了需求变更，但是你却没有用灵活的设计方法去应对，而是通过硬编码的方式在既有代码上打补丁，那么这就是设计不足。

因此，是否要使用各种设计原则和设计模式去设计一个非常灵活的程序，主要是看你的需求场景。

但是场景也会变化，一开始不需要复用，但是后来又需要复用了，那么就需要在复用的第一个场景去重构代码，而不是等将来困难局面 hold 不住了再重构。

对于软件开发而言，复杂的永远是业务逻辑，而不是设计模式。设计模式是可重复的，可重复的东西即使看起来复杂，熟悉了就会觉得很简单。

最终，一切都要看场景，只有合适的设计，不存在好的设计。

### 21 | 分布式架构：如何应对高并发的用户请求

垂直伸缩与水平伸缩

所谓的垂直伸缩就是提升单台服务器的处理能力，比如用更快频率的 CPU，用更多核的 CPU，用更大的内存，用更快的网卡，用更多的磁盘组成一台服务器，使单台服务器的处理能力得到提升。

所谓的水平伸缩，指的是不去提升单机的处理能力，不使用更昂贵更快更厉害的硬件，而是使用更多的服务器，将这些服务器构成一个分布式集群，通过这个集群对外统一提供服务，以此来提高系统整体的处理能力。

互联网分布式架构演化

一个应用访问自己服务器上的数据库，访问自己服务器的文件系统，构成了一个单机系统，这个系统就可以满足少量用户使用了。

![分布式架构演化 1](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%201.jpg)

如果这个系统被证明业务上是可行的，是有价值的，那么用户量就会快速增长。这个时候服务器就不能够承受访问压力了，需要进行第一次升级，数据库与应用分离。

![分布式架构演化 2](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%202.jpg)

而随着用户进一步的增加，3 台服务器也不能够承受这样的压力了，那么就需要使用缓存改善性能。

![分布式架构演化 3](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%203.jpg)

缓存主要有分布式缓存和本地缓存两种。分布式缓存将多台服务器共同构成一个集群，存储更多的缓存数据，共同对应用程序提供缓存服务，提供更强大的缓存能力。

最主要的，应用通过访问缓存降低了对数据库的访问压力，而数据库通常是整个系统的瓶颈所在。降低了数据库的访问压力，就是改善整个系统的处理能力。

随着用户的进一步增加，应用服务器可能又会成为瓶颈，因为连接大量的并发用户的访问，这时候就需要对应用服务器进行升级。通过负载均衡服务器，将应用服务器部署为一个集群，添加更多的应用服务器去处理用户的访问。

![分布式架构演化 4](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%204.jpg)

这时候的解决办法就是数据库的读写分离，将一个数据库通过数据复制的方式，分裂为两个数据库，主数据库主要负责数据的写操作，所有的写操作都复制到从数据库上，保证从数据库的数据和主数据库数据一致，而从数据库主要提供数据的读操作。

![分布式架构演化 5](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%205.jpg)

海量数据的存储，主要通过分布式数据库、分布式文件系统、NoSQL 数据库解决。直接在数据库上查询已经无法满足这些数据的查询性能要求，还需要部署独立的搜索引擎提供查询服务。同时减少数据中心的网络带宽压力，提供更好的用户访问延时，使用 CDN 和反向代理提供前置缓存，尽快返回静态文件资源给用户。

为了使各个子系统更灵活易于扩展，则使用分布式消息队列将相关子系统解耦，通过消息的发布订阅完成子系统间的协作。使用微服务架构将逻辑上独立的模块在物理上也独立部署，单独维护，应用系统通过组合多个微服务完成自己的业务逻辑，实现模块更高级别的复用，从而更快速地开发系统和维护系统。

![分布式架构演化 6](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%206.jpg)

### 22 | 缓存架构：如何减少不必要的计算？

所谓缓存，就是将需要多次读取的数据暂存起来，这样在后面应用程序需要多次读取的时候，就不必从数据源重复加载数据了，这样就可以降低数据源的计算负载压力，提高数据响应速度。

一般说来，缓存可以分成两种，通读缓存和旁路缓存。

通读（read-through）缓存，应用程序访问通读缓存获取数据的时候，如果通读缓存有应用程序需要的数据，那么就返回这个数据；如果没有，那么通读缓存就自己负责访问数据源，从数据源获取数据返回给应用程序，并将这个数据缓存在自己的缓存中。

旁路（cache-aside）缓存，应用程序访问旁路缓存获取数据的时候，如果旁路缓存中有应用程序需要的数据，那么就返回这个数据；如果没有，就返回空（null）。应用程序需要自己从数据源读取数据，然后将这个数据写入到旁路缓存中。

通读缓存

CDN（Content Delivery Network）即内容分发网络。

这个部署在网络服务商机房中的缓存就是 CDN，因为距离用户非常近，又被称作网络连接的第一跳。目前很多互联网应用大约 80% 以上的网络流量都是通过 CDN 返回的。

CDN 只能缓存静态数据内容，比如图片、CSS、JS、HTML 等内容。而动态的内容，比如订单查询、商品搜索结果等必须要应用服务器进行计算处理后才能获得。因此，互联网应用的静态内容和动态内容需要进行分离，静态内容和动态内容部署在不同的服务器集群上，使用不同的二级域名，即所谓的动静分离。

所有的请求都需要通过反向代理才能到达应用服务器，那么在这里加一个缓存，尽快将数据返回给用户，而不是发送给应用服务器，这就是反向代理缓存。

旁路缓存

应用程序在代码中主要使用的是对象缓存，对象缓存是一种旁路缓存。

程序中使用的对象缓存，可以分成两种。一种是本地缓存，缓存和应用程序在同一个进程中启动，使用程序的堆空间存放缓存数据。本地缓存的响应速度快，但是缓存可以使用的内存空间相对比较小。大型互联网应用需要缓存的数据通以 TB 计，这时候就要使用远程的分布式缓存了。

![分布式缓存架构](https://github.com/songor/interview/blob/master/picture/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84.jpg)

分布式缓存是指将一组服务器构成一个缓存集群，共同对外提供缓存服务，那么应用程序在每次读写缓存的时候，如何知道要访问缓存集群中的哪台服务器呢？

Memcached 将多台服务器构成一个缓存集群，缓存数据存储在每台服务器的内存中。事实上，使用缓存的应用程序服务器通常也是以集群方式部署的，每个程序需要依赖一个 Memcached 的客户端 SDK，通过 SDK 的 API 访问 Memcached 的服务器。

应用程序调用 API，API 调用 SDK 的路由算法，路由算法根据缓存的 key 值计算这个 key 应该访问哪台 Memcached 服务器，计算得到服务器的 IP 地址和端口号后，API 再调用 SDK 的通信模块将 \<key, value\> 值以及缓存操作命令发送给具体的某台 Memcached 服务器，由这台服务器完成缓存操作。

那么，路由算法又是如何计算得到 Memcached 的服务器 IP 端口呢？比较简单的一种方法，和 Hash 算法一样，利用 key 的 Hash 值对服务器列表长度取模，根据余数就可以确定服务器列表的下标，进而得到服务器的 IP 和端口。

缓存注意事项

首先就是数据脏读的问题，缓存的数据来自数据源，如果数据源中的数据被修改了，那么缓存中的数据就变成脏数据了。

主要解决办法有两个，一个是过期失效，每次写入缓存中的数据都标记其失效时间，在读取缓存的时候，检查数据是否已经过期失效，如果失效，就重新从数据源获取数据。另一个办法就是失效通知，应用程序更新数据源的数据，同时发送通知，将该数据从缓存中清除。

如果缓存的数据没有热点，写入缓存的数据很难被重复读取，那么使用缓存就不是很有必要了。

### 23 | 异步架构：如何避免互相依赖的系统间耦合？

使用消息队列实现异步架构

同步架构是说，当应用程序调用服务的时候，当前程序需要阻塞等待服务完成，返回服务结果后才能继续向下执行。

这种阻塞，一方面导致线程不能释放被占用的系统资源，导致系统资源不足，影响系统性能。另一方面，也导致无法快速给用户返回响应结果，用户体验较差。

消息队列的职责就是缓冲消息，等待消费者消费。根据消息消费方式又分为点对点模式和发布订阅模式两种。

在点对点模式中，多个消息生产者向消息队列发送消息，多个消息消费者消费消息，每个消息只会被一个消息消费者消费。

在发布订阅模式中，开发者可以在消息队列中设置主题，消息生产者的消息按照主题进行发送，多个消息消费者可以订阅同一个主题，每个消费者都可以收到这个主题的消息拷贝，然后按照自己的业务逻辑分别进行处理计算。

消息队列异步架构的好处

改善写操作请求的响应时间；更容易进行伸缩：将图片处理相关的操作（识别、分析、压缩等一些比较耗时的计算操作）放在消费者服务器上，那么就可以单独针对图片处理的消费者集群进行伸缩；削峰填谷；隔离失败；降低耦合：如果调用是同步的，那么意味着调用者和被调用者必然存在依赖，一方面是代码上的依赖，另一方面是结果的依赖。

消息队列实现异步架构是改善互联网应用写操作性能的重要手段，也是一种低耦合、易扩展的分布式应用架构模式。

### 24 | 负载均衡架构：如何用 10 行代码实现一个负载均衡服务？

HTTP 重定向负载均衡

![HTTP 重定向负载均衡](https://github.com/songor/interview/blob/master/picture/HTTP%20%E9%87%8D%E5%AE%9A%E5%90%91%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)

来自用户的 HTTP 请求到达负载均衡服务器以后，负载均衡服务器根据某种负载均衡算法计算得到一个应用服务器的地址，通过 HTTP 状态码 302 重定向响应，将新的 IP 地址发送给用户浏览器，用户浏览器收到重定向响应以后，重新发送请求到真正的应用服务器，以此来实现负载均衡。

HTTP 重定向负载均衡的优点是设计比较简单，但是它的缺点也比较明显，一方面用户完成一次访问，就需要请求两次数据中心，一次请求负载均衡服务器，一次是请求应用服务器，请求处理性能会受很大的影响。

另一个问题是因为响应要重定向到真正的应用服务器，所以需要把应用服务器的 IP 地址暴露给外部用户，这样可能会带来安全性的问题。

DNS 负载均衡

![DNS 负载均衡](https://github.com/songor/interview/blob/master/picture/DNS%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)

当用户从浏览器发起 HTTP 请求的时候，首先要到 DNS 域名服务器进行域名解析，解析得到 IP 地址以后，用户才能够根据 IP 地址建立 HTTP 连接，访问真正的数据中心的应用服务器，这时候就可以在 DNS 域名解析的时候进行负载均衡，也就是说，不同的用户进行域名解析的时候，返回不同的 IP 地址，从而实现负载均衡。

首先和 HTTP 重定向不同，用户不需要每次请求都进行 DNS 域名解析，第一次解析后，域名缓存在本机，后面较长一段时间都不会再进行域名解析了，因此性能方面不会是问题。

其次，如果如图中所示，域名解析直接得到应用服务器的 IP 地址，确实会存在安全性问题。但是大型互联网应用通常并不直接通过 DNS 解析得到应用服务器 IP 地址，而是解析得到负载均衡服务器的 IP 地址。也就是说，大型网互联网应用需要两次负载均衡，一次通过 DNS 负载均衡，用户请求访问数据中心负载均衡服务器集群的某台机器，然后这台负载均衡服务器再进行一次负载均衡，将用户请求分发到应用服务器集群的某台服务器上。通过这种方式，应用服务器不需要用公网 IP 将自己暴露给外部访问者，避免了安全性问题。

反向代理负载均衡

![反向代理负载均衡](https://github.com/songor/interview/blob/master/picture/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)

Nginx 这样的 HTTP 服务器就会同时提供反向代理与负载均衡功能。

反向代理服务器是工作在 HTTP 协议层之上的，所以它代理的也是 HTTP 的请求和响应。作为互联网应用层的一个协议，HTTP 协议相对说来比较重，效率比较低，所以反向代理负载均衡通常用在小规模的互联网系统上，只有几台或者十几台服务器的规模。

IP 负载均衡

![IP 负载均衡](https://github.com/songor/interview/blob/master/picture/IP%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)

它的主要工作原理是当用户的请求到达负载均衡服务器以后，负载均衡服务器会对网络层的数据包的 IP 地址进行转换，修改 IP 地址，将其修改为应用服务器的 IP 地址，然后把数据包重新发送出去，请求数据就会到达应用服务器。

IP 负载均衡不需要在 HTTP 协议层工作，可以在操作系统内核直接修改 IP 数据包的地址，因此，效率比应用层的反向代理负载均衡高得多。但是它依然有一个缺陷，不管是请求还是响应的数据包，都要通过负载均衡服务器进行 IP 地址转换，才能够正确地把请求数据分发到应用服务器，或者正确地将响应数据包发送到用户端程序。

数据链路层负载均衡

![数据链路层负载均衡](https://github.com/songor/interview/blob/master/picture/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)

数据链路层负载均衡可以解决响应数据量大而导致的负载均衡服务器输出带宽不足的问题。也就是说，负载均衡服务器并不修改数据包的 IP 地址，而是修改数据链路层里的网卡 mac 地址，在数据链路层实现负载均衡。而应用服务器和负载均衡服务器都使用相同的虚拟 IP 地址，这样 IP 路由就不会受到影响，但是网卡会根据自己的 mac 地址，选择负载均衡服务器发送到自己网卡的数据包，交给对应的应用程序去处理，处理结束以后，当把响应的数据包发送到网络上的时候，因为 IP 地址没有修改过，所以这个响应会直接到达用户的浏览器，而不会再经过负载均衡服务器。

链路层负载均衡避免响应数据再经过负载均衡服务器，因而可以承受较大的数据传输压力，所以，目前大型互联网应用基本都使用链路层负载均衡。

Linux 上实现 IP 负载均衡和链路层负载均衡的技术是 LVS，目前 LVS 的功能已经集成到 Linux 中了，通过 Linux 可以直接配置实现这两种负载均衡。

### 25 | 数据存储架构：如何改善系统的数据存储能力？

在整个互联网系统架构中，承受着最大处理压力，最难以被伸缩的就是数据存储部分。

一方面，数据存储需要使用硬盘，而硬盘的处理速度要慢一些；另一方面，数据是公司最重要的资产，公司需要保证数据的高可用以及一致性，非功能性约束更多一些。

数据库主从复制

![数据库主从复制](https://github.com/songor/interview/blob/master/picture/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.jpg)

MySQL 的主从复制，顾名思义就是将 MySQL 主数据库中的数据复制到从数据库中去。主要的复制原理是，当应用程序客户端发送一条更新命令到主服务器数据库的时候，数据库会把这条更新命令同步记录到 Binlog 中，然后由另外一个线程从 Binlog 中读取这条日志，通过远程通讯的方式将它复制到从服务器上面去。

从服务器获得这条更新日志后，将其加入到自己的 Relay Log 中，然后由另外一个 SQL 执行线程从 Relay log 中读取这条新的日志，并把它在本地的数据库中重新执行一遍，这样当客户端应用程序执行一个 update 命令的时候，这个命令会同时在主数据库和从数据库上执行，从而实现了主数据库向从数据库的复制，让从数据库和主数据库保持一样的数据。

通过数据库主从复制的方式，我们可以实现数据库读写分离。写操作访问主数据库，读操作访问从数据库，使数据库具有更强大的访问负载能力，支撑更多的用户访问。在实践中，通常采用一主多从的数据复制方案，也就是说，一个主数据库将数据复制到多个从数据库，多个从数据库承担更多的读操作压力，以及不同的角色，比如有的从数据库用来做实时数据分析，有的从数据库用来做批任务报表计算，有的单纯做数据备份。

采用一主多从的方案，当某个从数据库宕机的时候，还可以将读操作迁移到其他从数据库上，保证读操作的高可用。但如果主数据库宕机，系统就没法使用了，因此现实中，也会采用 MySQL 主主复制的方案。也就是说，两台服务器互相备份，任何一台服务器都会将自己的 Binlog 复制到另一台机器的 Relay Log 中，以保持两台服务器的数据一致。

![数据库主主复制](https://github.com/songor/interview/blob/master/picture/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%B8%BB%E5%A4%8D%E5%88%B6.jpg)

使用主主复制需要注意的是，主主复制仅仅用来提升数据写操作的可用性，并不能用来提高写操作的性能。任何时候，系统中都只能有一个数据库作为主数据库，也就是说，所有的应用程序都必须连接到同一个主数据库进行写操作。只有当该数据库宕机失效的时候，才会将写操作切换到另一台主数据库上。这样才能够保证数据库数据的一致性，不会出现数据冲突。

使用主主复制需要注意的是，主主复制仅仅用来提升数据写操作的可用性，并不能用来提高写操作的性能。任何时候，系统中都只能有一个数据库作为主数据库，也就是说，所有的应用程序都必须连接到同一个主数据库进行写操作。只有当该数据库宕机失效的时候，才会将写操作切换到另一台主数据库上。这样才能够保证数据库数据的一致性，不会出现数据冲突。

此外，不管是主从复制还是主主复制，都无法提升数据库的存储能力，也就是说，不管增加多少服务器，这些服务器存储的数据都是一样的。

数据库分片

也就是说，将一张表的数据分成若干片，每一片都包含了数据表中一部分的行记录，然后每一片存储在不同的服务器上，这样一张表就存储在多台服务器上了。

最简单的数据库分片存储可以采用硬编码的方式，在程序代码中直接指定一条数据库记录要存放到哪个服务器上。

但是硬编码方式的缺点比较明显。首先，如果要增加服务器，那么就必须修改分片逻辑代码，这样程序代码就会因为非业务需求产生不必要的变更；其次，分片逻辑耦合在处理业务逻辑的程序代码中，修改分片逻辑或者修改业务逻辑都可能使另一部分代码因为不小心的改动而出现 Bug。

但是我们可以通过使用分布式关系数据库中间件解决这个问题，将数据的分片逻辑在中间件中完成，对应用程序透明，比如 MYCAT。

实践中，更常见的数据库分片算法是我们所熟悉的余数 Hash 算法，根据主键 ID 和服务器的数目进行取模计算，根据余数连接相对应的服务器。

关系数据库的混合部署

单数据库：

![单数据库](https://github.com/songor/interview/blob/master/picture/%E5%8D%95%E6%95%B0%E6%8D%AE%E5%BA%93.jpg)

主从复制：

![主从复制](https://github.com/songor/interview/blob/master/picture/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.jpg)

业务分库：

![业务分库](https://github.com/songor/interview/blob/master/picture/%E4%B8%9A%E5%8A%A1%E5%88%86%E5%BA%93.jpg)

数据分片：

![数据分片](https://github.com/songor/interview/blob/master/picture/%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87.jpg)

NoSQL 数据库

NoSQL 数据库主要用来解决大规模分布式数据的存储问题。常用的 NoSQL 数据有 Apache HBase，Apache Cassandra 等，Redis 虽然是一个分布式缓存技术产品，但有时候也被归类为 NoSQL 数据库。

CAP 原理说：一个提供数据服务的分布式系统无法同时满足数据一致性（Consistency）、可用性（Availability）和分区耐受性（Partition Tolerance）这三个条件。

Apache Cassandra 解决数据一致性的方案是，在用户写入数据的时候，将一个数据写入集群中的三个服务器节点，等待至少两个节点响应写入成功。用户读取数据的时候，从三个节点尝试读取数据，至少等到两个节点返回数据，并根据返回数据的时间戳，选取最新版本的数据。这样，即使服务器中的数据不一致，但是最终用户还是能得到一个一致的数据，这种方案也被称为最终一致性。

### 26 | 搜索引擎架构：如何瞬间完成海量数据检索？

搜索引擎倒排索引

事实上，互联网一方面是将全世界的人和网络应用联系起来，另一方面，也将全世界的网页通过超链接联系起来，几乎每个网页都包含了一些其他网页的超链接，这些超链接互相链接，就让全世界的互联网构成了一个大的网络。所以，搜索引擎只需要解析这些网页，得到里面的超链接，然后继续下载这些超链接的网页，继续解析，这样就可以得到全世界的网页了。

这个过程具体是这样的：首先选择一些种子 URL，然后通过爬虫将这些 URL 对应的页面爬下来。其实，所谓的爬虫，就是发送 URL 请求下载相应的 HTML 页面，然后将这些 Web 页面存储在自己的服务器上，并解析这些页面的 HTML 内容，当解析到网页里超链接 URL 的时候，再检查这个超链接是否已经在前面爬取过了，如果没有，就把这个超链接放到一个队列中，后面会请求这个 URL，得到对应的 HTML 页面并解析其包含的超链接...如此不断重复，就可以将全世界的 Web 页面存储到自己的服务器中。

得到了全部网页以后，需要对每个网页进行编号，得到全部网页的文档集合。然后再解析每个页面，提取文档里的每个单词，如果是英文，那么每个单词都用空格分隔，比较容易；如果是中文，需要使用中文分词器才能提取到每个单词。然后考察每个词在哪些文档中出现，这样我们就可以得到一个单词、文档矩阵。把这个单词、文档矩阵按照单词、文档列表的方式组织起来，就是倒排索引了。

Google 将每个单词的文档列表存储在硬盘中，而对于文档数量没那么大的应用而言，文档列表也可以存储在内存中。每个单词记录下硬盘或者内存中的文档列表地址，搜索的时候，只要搜索到单词，就可以快速得到文档地址列表。根据列表中的文档编号，展示对应的文档信息，就完成了海量数据的快速检索。

而搜索单词的时候，我们可以将所有单词构成一个 Hash 表，根据搜索词直接查找 Hash 表，就可以得到单词了。

搜索引擎结果排序

Google 使用了一种叫 PageRank 的算法，计算每个网页的权重，搜索结果就按照权重排序，权重高的网页在最终结果显示的时候排在前面。

PageRank 算法认为，如果一个网页里包含了某个网页的超链接，那么就表示该网页认可某个网页，或者说，该网页给某个网页投了一票。

开始的时候，所有网页都初始化权重值为 1，然后根据超链接关系计算新的权重。比如 B 页面包含了 A 和 D 两个页面的超链接，那么自己的权重 1 就被分成两个 1/2 分别投给 A 和 D。而 A 页面的超链接包含在 B、C、D 三个页面中，那么 A 页面新的权重值就是这个三个页面投给它的权重值之和：1/2 + 1/3 + 1 = 11/6。

经过一轮 PageRank 计算后，每个页面都有了新的权重，然后基于这个新的权重再继续一轮计算，直到所有的网页权重稳定下来，就得到最终所有网页的权重，即最终的 PageRank 值。

通常，在一个网页中包含了另一个网页，是对另一个网页的认可，认为这个网页质量高，值得推荐。而被重要网页推荐的网页也应该是重要的，PageRank 算法就是对这一设想的实现，PageRank 值代表了一个网页受到的推荐程度，越受推荐越重要，就越是用户想看到的。基于每个网页的 PageRank 值对倒排索引中的文档列表进行排序，排在前面的文档通常也是用户想要看到的文档。

要对这些站内搜索引擎的结果进行排序，就需要利用其它一些信息以及算法，比如可以利用文章获得的点赞数进行排序，点赞越多，表示越获得其它用户的认可，越应该在搜索结果中排在前面。

除了用点赞数进行排序，有时候，我们更期望搜索结果按照内容和搜索词的相关性进行排序，这种情况可以使用词频 TF 进行排序，词频表示某个词在该文档中出现的频繁程度，也代表了这个词和该文档的相关程度。

### 27 | 微服务架构：微服务究竟是灵丹还是毒药？

单体架构的困难和挑战

编译、部署困难；代码分支管理困难；数据库连接耗尽；新增业务困难；发布困难

微服务框架原理

在面向服务的体系架构里面，服务提供者向注册中心注册自己的服务，而服务调用者到注册中心去发现服务，发现服务以后，根据服务注册中心提供的访问接口和访问路径对服务发起请求，由服务的提供者完成请求，返回结果给调用者。后来的各种微服务框架，其实都可以认为是 SOA 架构的一种实现。但是在早期的 SOA 架构实践中，WSDL、SOAP 这些协议都比较重，服务的注册与发现描述协议很复杂，服务的调用效率也比较低。

![Dubbo 架构](https://github.com/songor/interview/blob/master/picture/Dubbo%20%E6%9E%B6%E6%9E%84.jpg)

Dubbo 架构和 SOA 架构一样，最核心的组件也是 3 个，分别是服务提供者、服务消费者和服务注册中心。服务的提供者顾名思义就是微服务的具体提供者，通过微服务容器对外提供服务，而服务的消费者就是应用系统或是其他的微服务。

具体过程是服务的提供者程序在 Dubbo 的服务容器中启动，通过服务管理容器向服务注册中心进行注册，声明服务提供者提供的接口参数和规范，并且注册自己所在服务器的 IP 地址和端口。

服务的消费者如果想要调用某个服务，只需依赖服务提供者的接口进行编程即可。而服务接口通过 Dubbo 框架的代理访问机制，调用 Dubbo 的服务框架客户端，服务框架客户端会根据服务接口声明，去注册中心查找对应的服务提供者启动在哪些服务器上，并且将这个服务器列表返回给客户端。客户端根据某种负载均衡策略，选择某一个服务器，通过远程通讯模块发送具体的服务调用请求。

服务调用请求通过 Dubbo 底层自己的远程通讯模块，也就是 RPC 调用方式，将请求发送到服务的提供者服务器，服务提供者服务器收到请求以后，将该请求发送给服务提供者程序完成服务的执行，并将服务执行处理结果通过远程调用通讯模块 RPC 返回给服务消费者客户端，服务消费者客户端将结果返回给服务调用程序，从而完成远程服务的调用，获得服务处理的结果。

微服务架构的落地实践

微服务本身和业务强相关，如果业务关系没梳理好，模块设计不清晰，使用微服务架构很可能得不偿失，带来各种挫折。

### 28 | 高性能架构：除了代码，你还可以在哪些地方优化性能？

性能指标

所谓响应时间，是指从发出请求开始到收到最后响应数据所需要的时间。响应时间是系统最重要的性能指标，最直接地反映了系统的快慢。

并发数是指系统同时处理的请求数，这个数字反映了系统的负载压力情况。性能测试的时候，通常在性能压测工具中，用多线程模拟并发用户请求，每个线程模拟一个用户请求，这个线程数就是性能指标中的并发数。

吞吐量是指单位时间内系统处理请求的数量，体现的是系统的处理能力。我们一般用每秒 HTTP 请求数 HPS、每秒事务数 TPS、每秒查询数 QPS 这样的一些指标来衡量。

吞吐量、响应时间和并发数三者之间是有关联性的。并发数不变，响应时间足够快，那么单位时间的吞吐量就会相应的提高。

性能计数器，指的是服务器或者操作系统性能的一些指标数据，包括系统负载 System Load、对象和线程数、内存使用、CPU 使用、磁盘和网络 I/O 使用等指标，这些指标是系统监控的重要参数，反映系统负载和处理能力的一些关键指标，通常这些指标和性能是强相关的。这些指标很高，成为瓶颈，通常也预示着性能可能会出现问题。在实践中运维和开发人员会对这些性能指标设置一些报警的阈值。

性能测试

性能测试是指以系统设计初期规划的性能指标为预期目标，对系统不断地施加压力，验证系统在资源可接受的范围内是否达到了性能的预期目标。这个过程中，随着并发数的增加，吞吐量也在增加，但是响应时间变化不大。系统正常情况下的并发访问压力应该都在这个范围内。

负载测试则是对系统不断地施加并发请求，增加系统的压力，直到系统的某项或多项指标达到安全临界值。这个过程中，随着并发数的增加，吞吐量只有小幅的增加，达到最大值后，吞吐量还会下降，而响应时间则会不断增加。

压力测试是指在超过安全负载的情况下，增加并发请求数，对系统继续施加压力，直到系统崩溃，或者不再处理任何请求，此时的并发数就是系统的最大压力承受能力。这个过程中，吞吐量迅速下降，响应时间迅速增加，到了系统崩溃点，吞吐量为 0，响应时间无穷大。

性能压测工具不断增加并发请求线程数，持续对系统进行性能测试、负载测试、压力测试，得到对应的 TPS 和响应时间，将这些指标画在一个坐标系里，就得到系统的性能特性曲线。

![性能特性曲线](https://github.com/songor/interview/blob/master/picture/%E6%80%A7%E8%83%BD%E7%89%B9%E5%BE%81%E6%9B%B2%E7%BA%BF.jpg)

稳定性测试是指持续地对被测试系统施加一定的并发访问压力，使系统运行较长一段时间，以此检测系统是否稳定。通常，线上系统的负载压力是不稳定的，有时候，为了更好地模拟线上访问压力，稳定性测试的并发访问压力也可以不断调整压测线程数，在不稳定的并发压力下，测试系统的稳定性。

性能优化

用户体验优化：性能优化的最终目的是让用户有更好的性能体验，所以性能优化最直接的其实是优化用户体验。

第一层：数据中心优化

现在大型的互联网应用基本都采用多数据中心方案，在全球各个主要区域都部署自己的数据中心，就近为区域用户提供服务，加快响应速度。

第二层：硬件优化

事实上，即便使用水平伸缩，在分布式集群服务器内部，依然可以使用垂直伸缩，优化服务器的硬件能力。有时候，硬件能力的提升，对系统性能的影响是非常巨大的。

第三层：操作系统优化

不同操作系统以及操作系统内的某些特性也会对软件性能有重要影响。

第四层：虚拟机优化

像 Java 这样的编程语言开发的系统是需要运行在 JVM 虚拟机里的，虚拟机的性能对系统的性能也有较大影响，特别是垃圾回收，可能会导致应用程序出现巨大的卡顿。

第五层：基础组件优化

比如 Web 容器，数据库连接池等等。

第六层：架构优化

缓存：通过从缓存读取数据，加快响应时间，减少后端计算压力，缓存主要是提升读的性能。

消息队列：通过将数据写入消息队列，异步进行计算处理，提升系统的响应时间和处理速度，消息队列主要是提升写的性能。

集群：将单一服务器进行伸缩，构建成一个集群完成同一种计算任务，从而提高系统在高并发压力时候的性能。

第七层：代码优化

当然最重要的还是利用各种设计模式和设计原则，开发清晰、易维护的代码。

### 29 | 高可用架构：我们为什么感觉不到淘宝应用升级时的停机？

高可用的度量

业界通常用多少个 9 来说明互联网应用的可用性。

一般说来，两个 9 表示系统基本可用，年度不可用时间小于 88 小时；3 个 9 是较高可用，年度不可用时间小于 9 个小时；4 个 9 是具有自动恢复能力的高可用，年度不可用时间小于 53 分钟；5 个 9 指极高的可用性，年度不可用时间小于 5 分钟。

可用性并不是越高越好，而是要根据产品策略寻找高可用投入产出的最佳平衡点。

可用性指标是对系统整体可用性的一个度量。在互联网企业中，为了更好地管理系统的可用性，界定好系统故障以后的责任，通常会用故障分进行管理。

高可用的架构

冗余备份

冗余备份是说，提供同一服务的服务器要存在冗余，即任何服务都不能只有一台服务器，服务器之间要互相进行备份，任何一台服务器出现故障的时候，请求可以发送到备份的服务器去处理。这样，即使某台服务器失效，在用户看来，系统依然是可用的。

负载均衡服务器通过心跳检测发现集群中某台应用服务器失效，然后负载均衡服务器就不将请求分发给这台服务器，对用户而言，也就感觉不到有服务器失效，系统依然可用。

数据库主主复制，也是一种冗余备份。

失败隔离

保证系统高可用的另一个策略是失败隔离，将失败限制在一个较小的范围之内，使故障影响范围不扩大。具体实现失败隔离的主要架构技术是消息队列。

一方面，消息的生产者和消费者通过消息队列进行隔离。如果消费者出现故障的时候，生产者可以继续向消息队列发送消息，而不会感知到消费者的故障，等消费者恢复正常以后再去从消息队列中消费消息，所以从用户处理的视角看，系统一直是可用的。

另一方面，由于分布式消息队列具有削峰填谷的作用，所以在高并发的时候，消息的生产者可以将消息缓冲在分布式消息队列中，消费者可以慢慢地从消息队列中去处理，而不会将瞬时的高并发负载压力直接施加到整个系统上，导致系统崩溃。也就是将压力隔离开来，使消息生产者的访问压力不会直接传递到消息的消费者，这样可以提高数据库等对压力比较敏感的服务的可用性。

同时，消息队列还使得程序解耦，将程序的调用和依赖隔离开来，我们知道，低耦合的程序更加易于维护，也可以减少程序出现 Bug 的几率。

限流降级

在高并发场景下，如果系统的访问量超过了系统的承受能力，可以通过限流对系统进行保护。限流是指对进入系统的用户请求进行流量限制，如果访问量超过了系统的最大处理能力，就会丢弃一部分的用户请求，保证整个系统可用，保证大部分用户是可以访问系统的。

有一些系统功能是非核心的，但是它也给系统产生了非常大的压力，解决办法就是在系统高并发的时候将这些非核心的功能关闭，将宝贵的系统资源留下来。

异地多活

也就是说将数据中心分布在多个不同地点的机房里，这些机房都可以对外提供服务，用户可以连接任何一个机房进行访问，这样每个机房都可以提供完整的系统服务，即使某一个机房不可使用，系统也不会宕机，依然保持可用。

异地多活的架构考虑的重点就是，用户请求如何分发到不同的机房去。这个主要可以在域名解析的时候完成，也就是用户进行域名解析的时候，会根据就近原则或者其他一些策略，完成用户请求的分发。另一个至关重要的技术点是，因为是多个机房都可以独立对外提供服务，所以也就意味着每个机房都要有完整的数据记录。用户在任何一个机房完成的数据操作，都必须同步传输给其他的机房，进行数据实时同步。

数据库实时同步最需要关注的就是数据冲突问题。同一条数据，同时在两个数据中心被修改了，该如何解决？为了解决这种数据冲突的问题，某些容易引起数据冲突的服务采用类似 MySQL 的主主模式，也就是说多个机房在某个时刻是有一个主机房的，某些请求只能到达主机房才能被处理，其他的机房不处理这一类请求，以此来避免关键数据的冲突。

### 30 | 安全性架构：为什么说用户密码泄漏是程序员的锅？

数据加解密

用户密码加密通常使用的是单向散列加密。所谓的单向散列加密是指对一串明文信息进行散列（hash）加密，得到的密文信息是不可以被解密的，也就是说给定一个密文，即使是加密者也无法知道它的明文是什么的，加密是单向的，不支持解密。

单向散列加密事实上是一种 hash 算法，我们熟悉的 MD5 算法就是一种单向散列加密算法。单向散列算法虽然无法通过对密文进行解密计算还原得到原始明文，但是，如果知道了算法，就可以通过彩虹表的方法进行破解。

因此在实践中，使用单向散列算法加密还需要在计算过程中加点“盐” salt，如果黑客不知道加的“盐”是什么，就无法建立彩虹表还原得到明文。

对称加密，顾名思义，就是使用一个加密算法和一个密钥，对一段明文进行加密以后得到密文，然后使用相同的密钥和对应的解密算法，对密文进行解密，就可以计算得到明文。对称加密主要用于加密一些敏感信息，对敏感信息进行数据传输和存储，但是在使用的时候，必须要解密得到明文信息的一些场景。

所谓的非对称加密是指在加密的时候使用一个加密算法和一个加密密钥进行加密，得到一个密文。在解密的时候，必须使用解密算法和解密密钥进行解密才能够还原得到明文，加密密钥和解密密钥完全不同。通常加密密钥被称作公钥，解密密钥被称作私钥。

非对称加密的典型应用场景，就是我们常见的 HTTPS。

由于非对称加密需要消耗的计算资源比较多，效率也比较差，HTTPS 并不是每次请求响应都用非对称加密，而是先利用非对称加密在客户端和服务器之间交换一个对称加密的密钥，然后每次请求响应都用对称加密。这样，用非对称加密保证对称加密密钥的安全，再用对称加密密钥保证请求响应数据的安全。

使用非对称加密，还可以实现数字签名。用数字签名的时候是反过来的，自己用私钥进行加密，得到一个密文，但是其他人可以用公钥将密文解开，因为私钥只有自己才拥有，所以等同于签名。一段经过自己私钥加密后的文本，文本内容就等于是自己签名认证过的。

HTTP 攻击与防护

SQL 注入攻击就是攻击者在提交的请求参数里面包含有恶意的 SQL 脚本，最有效的防攻击手段是 SQL 预编译。

XSS 攻击即跨站点脚本攻击，攻击者构造恶意的浏览器脚本文件，使其在其他用户的浏览器上运行，进而进行攻击。

XSS 攻击防御的主要手段是消毒，检查用户提交的请求中是否含有可执行的脚本，因为大部分的攻击请求都包含 JS 等脚本语法，所以可以通过 HTML 转义的方式，对比较有危险的脚本语法关键字进行转义。

由于 HTTP 攻击必须以 HTTP 请求的方式提交到服务器，因此可以在服务器的入口统一进行拦截，对含有危险信息的请求进行消毒转义，或者直接拒绝请求。

针对 Web 应用防火墙，我们可以自己开发一个统一的请求过滤器进行拦截，也可以使用 ModSecurity 这样的开源 WAF（Web Application Firewall）。

### 31 | 大数据架构：大数据技术架构的思想和原理是什么？

大数据技术其实是分布式技术在数据处理领域的创新性应用，本质和我们此前讲到的分布式技术思路一脉相承：用更多的计算机组成一个集群，提供更多的计算资源，从而满足更大的计算压力要求。

分布式文件存储 HDFS 架构

HDFS 可以将数千台服务器组成一个统一的文件存储系统，其中 NameNode 服务器充当文件控制块的角色，进行文件元数据管理，即记录文件名、访问权限、数据存储地址等信息，而真正的文件数据则存储在 DataNode 服务器上。

DataNode 以块为单位存储数据，所有的块信息，比如块 ID、块所在的服务器 IP 地址等都记录在 NameNode，而具体的块数据则存储在 DataNode 上。理论上，NameNode 可以将所有 DataNode 服务器上的所有数据块都分配给一个文件，也就是说，一个文件可以使用所有服务器的硬盘存储空间，达到数百 P 的大小。

此外，HDFS 为了保证不会因为硬盘或者服务器损坏而导致文件损坏，还会对数据块进行复制，每个数据块都会存储在多台服务器上，甚至多个机架上。

大数据计算 MapReduce 架构

MapReduce 的核心思想是对数据进行分片计算。

MapReduce 将同一个计算程序启动在分布式集群的多台服务器上，每个服务器上的程序进程都读取本服务器上要处理的数据块进行计算，因此，大量的数据就可以同时进行计算了。

MapReduce 将计算过程分成两个部分，一个是 map 过程，每个服务器上会启动多个 map 进程，map 优先读取本地数据进行计算，计算后输出一个 \<key, value\> 集合。另一个是 reduce 过程，MapReduce 在每个服务器上都启动多个 reduce 进程，然后对所有 map 输出的 \<key, value\> 集合进行 shuffle 操作。所谓 shuffle 就是将相同的 key 发送到同一个 reduce 进程，在 reduce 中完成数据关联计算。

HDFS 和 MapReduce 都是 Hadoop 的组成部分。

大数据仓库 Hive 架构

Hive 要做的就是将 SQL 翻译成 MapReduce 程序代码，实际上，Hive 内置了很多 Operator，每个 Operator 完成一个特定的计算过程，Hive 将这些 Operator 构造成一个有向无环图 DAG，然后根据这些 Operator 之间是否存在 shuffle 将其封装到 map 或者 reduce 函数，就可以提交给 MapReduce 执行了。

快速大数据计算 Spark 架构

Spark 在 MapReduce 基础上进行改进，主要使用内存进行中间计算数据存储，加快了计算执行时间，在某些情况下，性能可以提升上百倍。Spark 的主要编程模型是 RDD 弹性数据集。在 RDD 上定义了许多常见的大数据计算函数，利用这些函数，可以用极少的代码完成较为复杂的大数据计算。

大数据流计算架构

Spark Streaming 的架构原理是将实时流入的数据切分成小的一批一批的数据，然后将这些小的一批数据交给 Spark 执行。由于数据量比较小，Spark Streaming 又常驻系统，不需要重新启动，因此可以毫秒级完成计算，看起来像是实时计算一样。

### 32 | AI 与物联网架构：从智能引擎到物联网平台

大数据平台架构

大数据平台主要就是跨越需要长时间处理的大数据计算和需要实时响应的互联网应用之间的鸿沟，使系统成为一个完整的整体。

![大数据平台架构](https://github.com/songor/interview/blob/master/picture/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84.jpg)

整个大数据平台可以分为三个部分：数据采集、数据处理和数据输出。

首先要有数据，数据主要有两个来源，一方面是应用服务器以及前端 App 实时产生的数据、日志以及埋点采集的数据，另一方面是外部爬虫和第三方数据。

通过大数据平台的数据同步系统，这些数据导入到 HDFS 中。由于不同数据源格式不同，数据源存储系统不同，因此需要针对不同的数据源开发不同的同步系统。同时，为了能够更好地对写入到 HDFS 的数据进行分析和挖掘，还需要对这些数据进行清洗、转换，因此数据同步系统实际上承担的是传统数据仓库 ETL 的职责，即数据的抽取（Extract）、转换（Transform）、载入（Load）。

写入到 HDFS 的数据会被 MapReduce、Spark、Hive 等大数据计算框架执行。数据分析师、算法工程师提交 SQL 以及 MapReduce 或者 Spark 机器学习程序到大数据平台。大数据平台的计算资源通常总是不足的，因此这些程序需要在任务调度管理系统的调度下排队执行。

SQL 或者机器学习程序的计算结果写回到 HDFS，然后再通过数据同步系统导出到数据库，应用服务器就可以直接访问这些数据，在用户请求的时候为用户提供服务了。

所以有了大数据平台，用户产生的数据就会被大数据系统进行各种关联分析与计算，然后又应用于用户请求处理。

来自数据源的数据实时进入大数据流计算引擎 Spark Streaming 等，实时处理后写入数据库。

智能推荐算法

大数据平台只是提供了数据获取、存储、计算、应用的技术方案，真正挖掘出这些数据之间的关系，让数据发挥价值的是各种机器学习算法。这些各种算法中，最常见的大概就是智能推荐算法了。

基于人口统计的推荐；基于商品属性的推荐；基于用户的协同过滤推荐；基于商品的协同过滤推荐

物联网大数据架构

物联网的目标是万物互联，将我们生产生活有关的一切事物都通过物联网连接起来。

物联网架构的关键是终端设备数据的采集、处理与设备的智能控制，背后依然是大数据与 AI 算法。

![物联网大数据平台](https://github.com/songor/interview/blob/master/picture/%E7%89%A9%E8%81%94%E7%BD%91%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0.jpg)

终端设备负责采集现场数据，这些数据被汇总到智能网关，智能网关经过初步的转换、计算后将数据发送给物联网大数据平台，大数据平台通过消息队列接收发送上来的各种数据。

由于物联网终端设备在现场实时运行，需要实时控制，因此大数据平台也需要实时处理这些数据。大数据流计算引擎会从消息队列中获取数据进行实时处理。

对于一些简单的数据处理来说，流式计算利用配置好的规则进行计算就可以了，而复杂的处理还需要利用机器学习模型。机器学习模型是通过大数据平台离线计算得到的，而离线计算使用的数据则是流计算从消息队列中获取的。

流式计算的结果通常是终端设备的控制信息，这些信息通过设备管理组件被发送给智能网关，智能网关通过边缘计算产生最终的设备控制信号，控制终端智能设备的动作。而物联网管理人员也可以通过应用程序直接远程控制设备。