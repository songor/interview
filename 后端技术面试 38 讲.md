# 后端技术面试 38 讲

### 开篇词 | 掌握软件开发技术的第一性原理

太阳底下没有新鲜事，绝大多数新技术其实都脱胎于一些既有的技术体系。

如果你能建立起这套技术思维体系，掌握这套技术体系背后的原理，那么当你接触一个新技术的时候，就可以快速把握住这个新技术的本质特征和思路方法，然后用你的技术思维体系快速推导出这个新技术是如何实现的。这个时候你其实不需要去学习这个新技术了，而是去验证这个新技术，你会去看它的文档和代码，去验证它是不是和你推导、猜测的实现方式一致，而不是去学习它怎么用了。

物理学有一个第一性原理， 指的是根据一些最基本的物理学常量，从头进行物理学的推导，进而得到整个物理学体系。

第一性原理就是让我们抓住事物最本质的特征原理，依据事物本身的规律，去推导、分析、演绎事物的各种变化规律，进而洞悉事物在各种具体场景下的表现形式，而不是追随事物的表面现象，生搬硬套各种所谓的规矩、经验和技巧，以至于在各种纷繁复杂的冲突和纠结中迷失了方向。

第一性原理是一种思维方式，一种学习方式，一种围绕事物核心推动事物正确前进的做事方式。

### 01 | 程序运行原理：程序是如何运行又是如何崩溃的？

### 02 | 数据结构原理：Hash 表的时间复杂度为什么是 O(1)？

数组是最常用的数据结构，创建数组必须要内存中一块连续的空间，并且数组中必须存放相同的数据类型。

由于每个整型数据占据 4 个字节的内存空间，因此整个数组的内存空间地址是 1000～1039，根据这个，我们就可以轻易算出数组中每个数据的内存下标地址。利用这个特性，我们只要知道了数组下标，也就是数据在数组中的位置，比如下标 2，就可以计算得到这个数据在内存中的位置 1008，从而对这个位置的数据进行快速读写访问，时间复杂度为 O(1)。

随机快速读写是数组的一个重要特性，但是要随机访问数据，必须知道数据在数组中的下标。如果我们只是知道数据的值，想要在数组中找到这个值，那么就只能遍历整个数组，时间复杂度为 O(N)。

Hash 表的物理存储其实是一个数组，如果我们能够根据 Key 计算出数组下标，那么就可以快速在数组中查找到需要的 Key 和 Value。许多编程语言支持获得任意对象的 HashCode，比如 Java 语言中 HashCode 方法包含在根对象 Object 中，其返回值是一个 Int。我们可以利用这个 Int 类型的 HashCode 计算数组下标。最简单的方法就是余数法，使用 Hash 表的数组长度对 HashCode 求余， 余数即为 Hash 表数组的下标，使用这个下标就可以直接访问得到 Hash 表中存储的 Key、Value。

不同的 Key 有可能计算得到相同的数组下标，这就是所谓的 Hash 冲突，解决 Hash 冲突常用的方法是链表法。

### 03 | Java 虚拟机原理：JVM 为什么被称为机器（machine）？

### 04 | 网络编程原理：一个字符的互联网之旅

数据链路层就是将数据进行封装后交给物理层进行传输，主要就是将数据封装成数据帧，以帧为单位通过物理层进行通信，有了帧，就可以在帧上进行数据校验，进行流量控制。数据链路层会定义帧的大小，这个大小也被称为最大传输单元。

链路层负载均衡（LVS）

这种负载均衡模式也叫直接路由模式，在负载均衡服务器的 Linux 操作系统内核拿到数据包后，直接修改数据帧中的 mac 地址，将其修改为搜索服务器集群中某个服务器的 mac 地址，然后将数据重新发送回服务器集群所在的局域网，这个数据帧就会被某个真实的搜索服务器接收到。

负载均衡服务器和集群内的搜索服务器配置相同的虚拟 IP 地址，也就是说，在网络通信的 IP 层面，负载均衡服务器变更 mac 地址的操作是透明的，不影响 TCP/IP 的通信连接。所以真实的搜索服务器处理完搜索请求，发送应答响应的时候，就会直接发送回请求的 App 手机，不会再经过负载均衡服务器。

### 05 | 文件系统原理：如何用 1 分钟遍历一个 100TB 的文件？

文件系统

文件系统将硬盘空间以块为单位进行划分，每个文件占据若干个块，然后再通过一个文件控制块 FCB 记录每个文件占据的硬盘数据块。

这个文件控制块在 Linux 操作系统中就是 inode，要想访问文件，就必须获得文件的 inode 信息，在 inode 中查找文件数据块索引表，根据索引中记录的硬盘地址信息访问硬盘，读写数据。

inode 中记录着文件权限、所有者、修改时间和文件大小等文件属性信息，以及文件数据块硬盘地址索引。inode 是固定结构的，能够记录的硬盘地址索引数也是固定的，只有 15 个索引。其中前 12 个索引直接记录数据块地址，第 13 个索引记录索引地址，也就是说，索引块指向的硬盘数据块并不直接记录文件数据，而是记录文件数据块的索引表，每个索引表可以记录 256 个索引；第 14 个索引记录二级索引地址，第 15 个索引记录三级索引地址，如下图：

![inode 文件控制块](https://github.com/songor/interview/blob/master/picture/inode%20%E6%96%87%E4%BB%B6%E6%8E%A7%E5%88%B6%E5%9D%97.jpg)

这样，每个 inode 最多可以存储 12+256+256\*256+256\*256\*256 个数据块，如果每个数据块的大小为 4k，也就是单个文件最大不超过 70G，而且即使可以扩大数据块大小，文件大小也要受单个硬盘容量的限制。

RAID

RAID，即独立硬盘冗余阵列，将多块硬盘通过硬件 RAID 或者软件 RAID 的方案管理起来，使其共同对外提供服务。RAID 的核心思路其实是利用文件系统将数据写入硬盘中不同数据块的特性，将多块硬盘上的空闲空间看做一个整体进行数据写入，也就是说，一个文件的多个数据块可能写入多个硬盘。

根据硬盘组织和使用方式不同，常用 RAID 有五种，分别是 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。

RAID 0 将一个文件的数据分成 N 片，同时向 N 个硬盘写入，这样单个文件可以存储在 N 个硬盘上，文件容量可以扩大 N 倍，（理论上）读写速度也可以扩大 N 倍。但是使用 RAID 0 的最大问题是文件数据分散在 N 块硬盘上，任何一块硬盘损坏，就会导致数据不完整，整个文件系统全部损坏，文件的可用性极大地降低了。

RAID 1 则是利用两块硬盘进行数据备份，文件同时向两块硬盘写入，这样任何一块硬盘损坏都不会出现文件数据丢失的情况，文件的可用性得到提升。

RAID 10 结合 RAID 0 和 RAID 1，将多块硬盘进行两两分组，文件数据分成 N 片，每个分组写入一片，每个分组内的两块硬盘再进行数据备份。这样既扩大了文件的容量，又提高了文件的可用性。但是这种方式硬盘的利用率只有 50%，有一半的硬盘被用来做数据备份。

RAID 5 针对 RAID 10 硬盘浪费的情况，将数据分成 N-1 片，再利用这 N-1 片数据进行位运算，计算一片校验数据，然后将这 N 片数据写入 N 个硬盘。这样任何一块硬盘损坏，都可以利用校验片的数据和其他数据进行计算得到这片丢失的数据，而硬盘的利用率也提高到 N-1/N。

RAID 5 可以解决一块硬盘损坏后文件不可用的问题，那么如果两块硬盘损坏呢？RAID 6 的解决方案是，用两种位运算校验算法计算两片校验数据，这样两块硬盘损坏还是可以计算得到丢失的数据片。

实践中，使用最多的是 RAID 5，数据被分成 N-1 片并发写入 N-1 块硬盘，这样既可以得到较好的硬盘利用率，也能得到很好的读写速度，同时还能保证较好的数据可用性。使用 RAID 5 的文件系统比简单的文件系统文件容量和读写速度都提高了 N-1 倍，但是一台服务器上能插入的硬盘数量是有限的，通常是 8 块，也就是文件读写速度和存储容量提高了 7 倍，这远远达不到 1 分钟完成 100T 文件的遍历要求。

分布式文件系统

Linux 的文件系统：文件的基本信息，也就是文件元信息记录在文件控制块 inode 中，文件的数据记录在硬盘的数据块中，inode 通过索引记录数据块的地址，读写文件的时候，查询 inode 中的索引记录得到数据块的硬盘地址，然后访问数据。

如果将数据块的地址改成分布式服务器的地址呢？也就是查询得到的数据块地址不只是本机的硬盘地址，还可以是其他服务器的地址，那么文件的存储容量就将是整个分布式服务器集群的硬盘容量，这样还可以在不同的服务器上同时并行读取文件的数据块，文件访问速度也将极大地加快。

这样的文件系统就是分布式文件系统，分布式文件系统的思路其实和 RAID 是一脉相承的，就是将数据分成很多片，同时向 N 台服务器上进行数据写入。针对一片数据丢失就导致整个文件损坏的情况，分布式文件系统也是采用数据备份的方式，将多个备份数据片写入多个服务器，以保证文件的可用性。当然，也可以采用 RAID 5 的方式通过计算校验数据片的方式提高文件可用性。

HDFS 的关键组件有两个，一个是 DataNode，一个是 NameNode。

DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分割成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分布存储在整个 HDFS 服务器集群中。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得 HDFS 可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。在实践中，HDFS 集群的 DataNode 服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块硬盘，整个集群的存储容量大概在几 PB 到数百 PB。

NameNode 负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、访问权限、数据块的 ID 以及存储位置等信息，相当于 Linux 系统中 inode 的角色。HDFS 为了保证数据的高可用，会将一个数据块复制为多份（缺省情况为 3 份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有硬盘损坏，或者某个 DataNode 服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。

有了 HDFS，可以实现单一文件存储几百 T 的数据，再配合大数据计算框架 MapReduce 或者 Spark，可以对这个文件的数据块进行并发计算。也可以使用 Impala 这样的 SQL 引擎对这个文件进行结构化查询，在数千台服务器上并发遍历 100T 的数据，1 分钟都是绰绰有余的。

总结

文件系统从简单操作系统文件，到 RAID，再到分布式文件系统，其设计思路其实是具有统一性的。这种统一性一方面体现在文件数据如何管理，也就是如何通过文件控制块管理文件的数据，这个文件控制块在 Linux 系统中就是 inode，在 HDFS 中就是 NameNode。

另一方面体现在如何利用更多的硬盘实现越来越大的文件存储需求和越来越快的读写速度需求，也就是将数据分片后同时写入多块硬盘。单服务器我们可以通过 RAID 来实现，多服务器则可以将这些服务器组成一个文件系统集群，共同对外提供文件服务，这时候，数千台服务器的数万块硬盘以单一存储资源的方式对文件使用者提供服务，也就是一个文件可以存储数百 T 的数据，并在一分钟完成这样一个大文件的遍历。

思考题

RAID5 中，校验位之所以螺旋式地落在所有硬盘上，主要原因是如果将校验位记录在同一块硬盘上，那么对于其他多块数据盘，任何一块硬盘修改数据都需要修改这个校验盘上的校验数据，也就是说，对于有 8 块硬盘的 RAID5 阵列，校验盘的数据写入压力是其他数据盘的 7 倍。而硬盘的频繁写入会导致硬盘寿命缩短，校验盘会频繁损坏，存储的整体可用性和维护性都会变差。

### 06 | 数据库原理：为什么 PreparedStatement 性能更好更安全？

SQL 执行过程

一个 SQL 提交到数据库，经过连接器将 SQL 语句交给语法分析器，生成一个抽象语法树 AST；AST 经过语义分析与优化器，进行语义优化，使计算过程和需要获取的中间数据尽可能少，然后得到数据库执行计划；执行计划提交给具体的执行引擎进行计算，将结果通过连接器再返回给应用程序。

使用 PreparedStatement 执行 SQL 的好处

一个是 PreparedStatement 会预先提交带占位符的 SQL 到数据库进行预处理，提前生成执行计划，当给定占位符参数真正执行 SQL 的时候，执行引擎可以直接执行，效率更好一点。

另一个好处则更为重要，PreparedStatement 可以防止 SQL 注入攻击。

因为一开始构造 PreparedStatement 的时候就已经提交了查询 SQL，并被数据库预先生成好了执行计划，后面黑客不管提交什么样的字符串，都只能交给这个执行计划去执行，不可能再生成一个新的 SQL 了，也就不会被攻击了。

### 07 | 编程语言原理：面向对象编程是编程的终极形态吗？

### 答疑 | Java Web 程序的运行时环境到底是怎样的？

首先，我们是通过执行 Tomcat 的 Shell 脚本启动 Tomcat 的，而在 Shell 脚本里，其实启动的是 Java 虚拟机，大概是这样一个 Shell 命令：

`java org.apache.catalina.startup.Bootstrap "$@" start`

所以我们在 Linux 操作系统执行 Tomcat 的 Shell 启动脚本，Tomcat 启动以后，其实在操作系统里看到的是一个 JVM 虚拟机进程。这个虚拟机进程启动以后，加载 class 进来执行，首先加载的就这个 org.apache.catalina.startup.Bootstrap 类，这个类里面有一个 main() 函数，是整个 Tomcat 的入口函数，JVM 虚拟机会启动一个主线程从这个入口函数开始执行。

主线程从 Bootstrap 的 main() 函数开始执行，初始化 Tomcat 的运行环境，这时候就需要创建一些线程，比如负责监听 80 端口的线程，处理客户端连接请求的线程，以及执行用户请求的线程。创建这些线程的代码是 Tomcat 代码的一部分。

初始化运行环境之后，Tomcat 就会扫描 Web 程序路径，扫描到开发的 war 包后，再加载 war 包里的类到 JVM。因为 Web 应用是被 Tomcat 加载运行的，所以我们也称 Tomcat 为 Web 容器。

如果有外部请求发送到 Tomcat，也就是外部程序通过 80 端口和 Tomcat 进行 HTTP 通信的时候，Tomcat 会根据 war 包中的 web.xml 配置，决定这个请求 URL 应该由哪个 Servlet 处理，然后 Tomcat 就会分配一个线程去处理这个请求，实际上，就是这个线程执行相应的 Servlet 代码。

如果 Tomcat 的线程在执行代码时抛出未处理的异常，那么当前线程就会结束执行，这时控制台看到的异常信息就是线程堆栈信息，线程会把异常信息以及当前堆栈的方法都打印出来。事实上，这个异常最后还是会被 Tomcat 捕获，然后 Tomcat 会给客户端返回一个 500 错误。单个线程的异常不影响其他线程执行，也就是不影响其他请求的处理。

但是如果线程在执行代码的时候抛出的是 JVM 错误，比如 OutOfMemoryError，这个时候看起来是应用 crash，事实上是整个进程都无法继续执行了，也就是进程 crash 了，进程内所有应用都不会被继续执行了。