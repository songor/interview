# 分布式技术面试大厂真题 30 讲

### 分布式基础篇

* 谈谈你对分布式的理解，为什么引入分布式？

  * 面试官：谈谈你对分布式系统的理解

    什么是分布式系统：

    为了解决传统单体服务架构带来的各种问题，代码数量庞大，迭代测试维护困难，可能因为一处改动测试不到位造成整个服务瘫痪等问题，分布式系统就是将一个大的服务拆分成几十个甚至上百个微小的服务。如果把单体架构服务器比做篮子，那代码就是鸡蛋，不要让所有鸡蛋装在一个篮子里，也方便大家分工开发，代码不在一个项目里，也不会冲突。

    比如 Dubbo、Spring Cloud，都是解决分布式微服务架构的优秀框架。

  * 面试官：分布式系统环境下各自有什么优缺点？

    优点：

    **系统可用性提升**，一个系统全年可用时间在 99.999%，5 个 9 的服务可用率在设计合理的分布式系统中并不是一个触不可及的数字。

    **系统并发能力提升**，请求通过 Nginx 负载均衡被分发到不同的服务器上，运行同样代码的服务器可以有 1 台或 N 台，通常情况下会根据实际用户访问量随时增加机器，无论是数据库或者服务，都可以做到随时水平扩展。

    **系统容错能力提升**，同一组服务分别部署在北京上海杭州，杭州的机房突发断电或者火灾，杭州机房的流量会被自动分发到北京和上海的机房，不影响用户使用。

    **低延迟**，北京的用户请求自动分发到北京，上海的用户请求被分发到上海，服务器会根据用户的 IP 选择距离自己最近的机房，降低网络延迟。

    缺点：

    **分布式服务依赖网络**，服务器间通讯依赖网络，不可靠网络包括网络延时，丢包、中断、异步，一个完整的服务请求依赖一连串服务调用，任意一个服务节点网络出现问题，都可能造成本次请求失败。

    **维护成本高**，传统单体式服务只需要维护一个站点就可以。分布式服务系统被拆分成若干个小服务，服务从 1 变为几十个上百个服务后，增加运维成本。

    **一致性，可用性，分区容错性无法同时满足**，这三种特性就是平时说的 CAP 定理，在分布式系统中，这三种特性最多只能满足两种，无法同时满足，需要根据实际情况去调整牺牲掉其中哪个。

    深入分析：

    关于分布式系统，通俗点讲就把整个业务系统拆分成很多的服务，每个服务责任到人，服务之间代码都没有冲突，服务可以自治，每个服务的技术也可以自己选型，只要遵循统一的服务调用协议就可以了。每次发布如果只改动一个服务那就上线一个服务，不用所有人一起联调，这样每次发布牵扯到的改动影响也是可控的。不像传统单体架构服务，动辄几百万行代码融在一起。

    分布式系统并不是某一门具体的技术，也不是具体的框架。用大白话理解就是将计算能力和数据存储能力分散在不同服务器上，通过网络连接组成的一个整体的服务，不同服务器可能是物理机，也可能是虚拟机，分布式的概念可以理解成一种解决方案。

    分布式系统总结来说是将数据存储能力和计算能力分布到不同的服务器上，作为一个整体对外服务。目的在于解决单台机器的故障问题，单机计算和 IO 性能问题，以及单机存储空间不足的问题。虽然单机故障的概率比较小，但是随着集群规模大了之后，集群宕机和磁盘损坏基本上是常态，分布式系统主要解决的是各种故障带来的问题。

  * 分布式系统和微服务什么关系

    关于分布式系统和微服务，两者都只是一种概念。如果你采用微服务，就意味着系统一定是分布式的，分布式系统具有的优缺点在微服务里都会体现，个人理解微服务是分布式系统的一种具体落地方案。
    
  * 分布式系统一定是集群的吗？

    还要先理解两者的概念。其实分布式不一定就是不同的组件，同一个组件也可以，关键在于是否通过交换信息的方式进行协作。比如说 Zookeeper 的节点都是对等的，但它自己就构成一个分布式系统。也就是说，分布式是指通过网络连接的多个组件，通过交换信息协作而形成的系统。而集群，是指同一种组件的多个实例，形成的逻辑上的整体。可以看出这两个概念并不完全冲突，分布式系统也可以是一个集群，例子就是前面说的 Zookeeper 等，它的特征是服务之间会互相通信协作。是分布式系统不是集群的情况，就是多个不同组件构成的系统；是集群不是分布式系统的情况，比如多个经过负载均衡的 HTTP 服务器，它们之间不会互相通信，如果不带上负载均衡的部分的话，一般不叫做分布式系统。 

* 公司使用什么 RPC 框架，聊聊你理解的 RPC 原理

  * 面试官：公司使用什么 RPC 框架？可以介绍一下 RPC 的工作原理吗？

    RPC 是一个分布式计算的 CS 模式，总是由 Client 向 Server 发出一个执行若干过程请求，Server 接受请求，使用客户端提供的参数，计算完成之后将结果返回给客户端。

    ![RPC 原理](https://github.com/songor/interview/blob/master/picture/RPC%20%E5%8E%9F%E7%90%86.jpg)

    服务集成 RPC 后，服务（这里的服务就是图中的 Provider，服务提供者）启动后会通过 Register（注册）模块，把服务的唯一 ID、IP 地址、端口信息等注册到 RPC 框架注册中心（图中的 Registry 部分）。

    当调用者（Consumer）想要调用服务的时候，通过 Provider 注册时的的服务唯一 ID 去注册中心查找在线可供调用的服务，返回一个 IP 列表（3.notify 部分）。

    Consumer 根据一定的策略，比如随机或轮询从 Registry 返回的可用 IP 列表中选择真正调用的服务（4.invoke）。

    RPC 框架都提供监控功能，监控服务健康状况，控制服务线上扩展和上下线（5.count）

  * 面试官：服务启动的时候服务基本信息被注册到注册中心，如果服务提供者挂了，注册中心如何知道服务不可用了呢？

    服务掉线分为主动下线和心跳检测。

    比如服务发新版本时，在重启之前主动通知注册中心，我要重启了，有流量进来不要分发给我，等我重启成功后再放流量进来，或者在管理后台手动摘掉机器，这个是主动下线。

    心跳检测是处理服务非正常下线（如断电断网）的情况。注册中心增加一个心跳检测功能，它会对服务提供者（Provider）进行心跳检测，比如每隔 30s 发送一个心跳，如果三次心跳结果都没有返回值，就认为该服务已下线，赶紧更新 Consumer 的服务列表，告诉 Consumer 调用别的机器。

  * 面试官：如果注册中心挂了，比如你用的是 Zookeeper，如果 Zookeeper 挂了，那服务之间还能相互调用吗？

    首先注册中心挂掉也要分两种情况，如果数据库挂了，ZK 还是能用的，因为 ZK 会缓存服务列表。

    其次 ZK 本身就是一个集群，一台机器挂了，ZK 会选举出集群中的其他机器作为 Master 继续提供服务，如果整个集群都挂了也没问题，因为调用者本地会缓存从注册中心获取的服务列表，省略和注册中心的交互，Consumer 和 Provider 采用直连方式，这些策略都是可配置的。

  * 面试官：能否自己写一个 RPC 框架？

    ![RPC 框架](https://github.com/songor/interview/blob/master/picture/RPC%20%E6%A1%86%E6%9E%B6.jpg)

    客户端 invoke 方法编写，使用 JDK 的动态代理技术，客户端调用远程服务方法时调用的是 InvocationHandler 的 invoke 方法。

    客户端 Filter 方法编写，完善的 RPC 框架少不了监控、路由、降级、鉴权等功能。创建 Socket，在 Filter 方法中实现 Client.write 方法，其逻辑为从连接池（Channel Pool）中获取连接，然后将数据写进 Channel。

    实现数据序列化、压缩，目的是减少网络传输的数据量，向服务端发送 request 数据，这里可以使用 Netty 异步通讯框架。

    服务端收到客户端发来的消息后，从 Channel 中将消息读出来之前，也会先经反序列化解压，请求就到了服务端 Filter 中，请求依次经过监控、鉴权方法。

    根据客户端传递来的服务信息和参数，通过反射调用相应的业务服务并拿到业务处理结果，然后在 ResponseFilter 中将返回结果写入 Channel。

    服务端序列化、压缩等，发送给客户端。

    客户端收到消息后，经过客户端反序列化、解压缩后交给 ResponseThreadPoolProcessor 线程池处理。ResponseThreadPoolProcessor 收到消息后，就将结果返回给之前的方法调用，整个调用请求就结束了。

  * 已经有 HTTP 协议接口，或者说 RESTful 接口，为什么还要使用 RPC 技术？

    在接⼝不多的情况下，使用 HTTP 确实是一个明智的选择，开发简单、测试也比较直接、部署方便，利用现成的 HTTP 协议进行系统间通讯。

    如果业务慢慢做大，系统也慢慢扩大，RPC 框架的好处就显示出来了：

    ⾸先 RPC 支持长链接，通信不必像 HTTP 一样每次去重复 3 次握⼿，减少了网络开销。

    其次 RPC 框架一般都有注册中心模块，有完善的监控管理功能，服务注册发现、服务下线、服务动态扩展等，服务化治理效率大大提高。

    基于 TCP 协议实现的 RPC，能更灵活地对协议字段进行定制，相比 HTTP 能减少网络传输字节数，降低网络开销（握手），提高性能，实现更大的吞吐量和并发数，但是需要更多地关注底层复杂细节， 对开发人员的要求也较高，增加开发成本。

* 详细说下 CAP 分别代表什么含义

  * 面试官：说到 CAP 定理，能详细说说 CAP 分别代表什么吗？

    Consistency - 一致性，Availability - 可用性，Partition tolerance - 分区容错性。

    一个分布式系统最多同时满足一致性，可用性和分区容错性这三项中的两项。

    深入分析：

    用 Redis Cluster 高可用架构举例，Redis 会将数据分片到多个实例（按照 slot 存储）中，即一个机房分担一部分数据。Master 负责写，Master 会自动同步到 Slave。

    ![Redis Cluster](https://github.com/songor/interview/blob/master/picture/Redis%20Cluster.jpg)

    无中心架构，三机房部署，其中一主一从构成一个分片，之间通过异步复制同步数据，异步复制存在数据不一致的时间窗口，保证可用性的同时牺牲了部分一致性。一旦某个机房掉线，则分片上位于另一个机房的 slave 会被提升为 master 从而可以继续提供服务。

    可扩展性，可线性扩展到 1000 多个节点，节点可动态添加或删除。

    消息的延迟会带来数据不一致问题，理想情况下消息不丢失那数据会最终一致。“最终一致性”，就是说不管消息延迟多久甚至丢失，设计一个离线定时任务，定期去扫描两个系统的数据，有不一致的情况就主动刷新同步，这样保证最终一致。

* 说一说什么是正向代理，反向代理

  * 面试官：使用 Nginx 做代理，你是如何理解正向代理，反向代理的？

    正向代理，代理用户端请求服务端，相对于服务器用户端是匿名的。比如单位内网使用了正向代理软件，所有员工都访问百度，但是百度看到的只有一个 IP 地址，百度也不知道到底是哪个员工访问的。

    反向代理，代理服务端提供服务，相对于用户服务端是匿名的。同样是访问百度，所有用户输入的都是一个域名或者一个 IP，但是百度背后有成千上万的服务器，你也不知道你访问的是哪一个。

  * 面试官：服务端为什么要使用代理？有啥好处？

    让 IO 和服务器分离，突破 IO 性能，提高服务器吞吐能力；

    控制流量分发，管理服务集群，起到负载均衡作用；

    安全性和匿名性，通过拦截前端服务器的请求，反向代理服务器可以保护其身份，并可以抵御安全攻击。它还确保可以从单个记录定位器或 URL 访问多个服务器，而不管服务端网络的结构如何。

  * 面试官：你知道哪些负载均衡算法？

    轮询算法：将多个用户请求按顺序依次分发到机器上，目的就是让每台机器承受相同的压力。

    加权轮询算法：设置不同机器的权重不同，10 台同配置机器分别均摊 10% 的流量，如果机器性能不同，让低配的机器权重降低，只承担 5% 的流量。

    随机算法：让所有请求随机分配到不同的机器上，请求越多最后分散在每台机器上的请求数约接近相等。

    加权随机算法：和加权轮询算法道理相似。

    最小连接数算法：请求分发之前，查看当前机器谁最清闲，谁当前处理的连接数最少，那就把活分给谁，最后的分工也相对公平。

    Hash 算法：前 5 种算法有一个问题，同一个用户的请求多次，可能每次都会被分配到不同的机器上，如果服务器缓存了用户 Session，那每次请求不同服务器都需要保存用户的 Session，最坏的结果就是每台服务器都缓存了同一个用户的 Session，这显然浪费了服务器资源。hash(client:ip) % N，N 就是服务器的数量，只要用户的 IP不变，最后 Hash 取余的结果就不会变，保证同一个用户每次请求都会在同一台机器上，这里的 IP 还可以是用户的其他唯一 ID。

    一致性 Hash 算法：hash(client:ip) % N，如果 N 变了怎么办？所有用户被分配到哪台机器需要全部重新计算，这对有 Session 状态的服务就是一场灾难。一致性 Hash 算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性 Hash 算法是对 2^32 取模，简单来说，一致性 Hash 算法将整个哈希值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，圆环的正上方的点代表 0，0 点右侧的第一个点代表 1，以此类推，2、3、4、5、6 ... 直到 2^32-1，也就是说 0 点左侧的第一个点代表 2^32-1，0 和 2^32-1 在零点中方向重合，我们把这个由 2^32 个点组成的圆环称为 Hash 环。将各个服务器进行哈希，具体可以选择服务器的 IP 或主机名作为关键字，这样每台机器就能确定其在哈希环上的位置。数据 key 使用相同的 hash 函数计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。一般的，在一致性 Hash 算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。一般的，在一致性 Hash 算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。

  * 深入分析

    * 什么是负载均衡

      简单地理解负载均衡的作用就是流量分发，将大量用户请求分发到不同服务器上分担压力，如果有机器宕机，负载均衡服务器会负责把故障机器自动摘除。

    * 常用的负载均衡框架

      Nginx，LVS，HAProxy，F5

### Redis 缓存篇

* Redis 中有哪些数据结构及底层实现原理

  * Redis 有什么优势吗？

    Redis 支持丰富的数据结构；

    Redis 是读写单进程单线程，不用考虑并发读写的复杂场景，速度也快；

    Redis 功能完备，支持数据持久化，支持主从复制和集群；

    还有 Lua 脚本，事务，发布订阅模型，Redis 都支持。

    通过将数据存储到离 CPU 更近的位置，减少数据传输时间，提高处理效率，这就是缓存的意义。

  * 为什么单线程模型的 Redis 性能不减

    单线程不代表一定就慢，单线程模型避免了多线程的频繁上下文切换，这也避免了多线程可能产生的竞争问题；

    Redis 是基于内存的读写操作；

    Redis 核心是基于非阻塞的 IO 多路复用机制。

  * Redis 数据结构有哪几种

    字符串 String：字符串是 Redis 中最为基础的数据存储类型，数据结构简单，可存储文本、Json、图片数据等任何二进制文件。

    列表 List：类似 Java 中的 List，按照插入顺序排序的字符串链表，在插入时，如果该键不存在，Redis 将为该键创建一个新的链表。如果链表中所有的元素均被移除，那么该键也将会从数据库中删除。

    集合 Set：类似 Java 中的 Set，它是一个无序集合，用于存储无序（存入和取出的顺序不一定相同）元素，值不能重复。可以使用 Redis 的 Set 数据类型跟踪一些唯一性数据。

    有序集合 Sorted Set：类似 Java 中的 TreeSet，支持从小到大排序的 Set，适用于排行榜结构的数据存储。

    Hash：类似于 Java 中的 HashMap，该类型非常适合于存储对象。

  * 深入分析

    * Redis 字符串的实现方式

      简单动态字符串（simple dynamic string）简称 SDS。Redis 使用 C 语言编写，但是传统的 C 字符串使用长度为 N+1 的字符串数组来表示长度为 N 的字符串，所以为了获取一个字符串的长度，必须遍历整个字符串。在动态字符串的数据结构中，有专门用于保存字符串长度的变量，我们可以通过获取 len 属性的值，直接知道字符串长度，从一定程度上提高了读取效率。

      ```c
      struct sdshdr {
          int len;
          int free;
          char buf[];
      };
      ```

    * List 底层结构

      链表数据结构。链表是常规的普通双端链表，可以支持反向查找和遍历，通过增删节点来灵活地调整链表的长度。

    * Sorted Set 底层结构

      Sorted Set 内部使用字典（HashMap）和跳跃表（SkipList）来保证数据的存储和有序，HashMap 里放的是成员到 score 的映射，而跳跃表里存放的是所有的成员，排序依据 HashMap 里存的 score，使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。

      如果我们只使用字典来实现有序集合，那么虽然以 O(1) 复杂度查找成员的分值这一特性会被保留，但是，因为字典以无序的方式来保存集合元素，所以每次在执行范围型操作 ZRANK 、ZRANGE 等命令时，程序都需要对字典保存的所有元素进行排序，完成这种排序需要至少 O(N \ log N) 时间复杂度，以及额外的 O(N) 内存空间（因为要创建一个数组来保存排序后的元素）。

      如果我们只使用跳跃表来实现有序集合，那么跳跃表执行范围型操作的所有优点都会被保留，但因为没有了字典，所以根据成员查找分值这一操作的复杂度将从 O(1) 上升为 O(log N) 。

      为了让有序集合的查找和范围型操作都尽可能快地执行，Redis 选择了同时使用字典和跳跃表两种数据结构来实现有序集合。

      跳跃表其实可以把它理解为多层的链表，它有如下的性质：

      多层的结构组成，每层是一个有序的链表；

      最底层的链表包含所有的元素；

      跳跃表的查找次数近似于层数，时间复杂度为 O(log N)，插入、删除也为 O(log N)；

      跳跃表是一种随机化的数据结构（通过抛硬币来决定层数）。

      ![跳跃表](https://github.com/songor/interview/blob/master/picture/%E8%B7%B3%E8%B7%83%E8%A1%A8.jpg)

    * 关于缓存的一些算法

      缓存数据淘汰策略：

      FIFO（First In First Out），先进先出算法，即先放入缓存的先被移除。

      LRU（Least Recently Used），最近最少使用算法，使用时间距离现在最久的被移除。

      LFU（Least Frequently Used），最不常用算法，一定时间段内使用次数（频率）最少的被移除。

      缓存数据更新策略：

      定时任务从数据库直接更新缓存，适用于对时间不敏感的数据。

      查询时写缓存，即查询优先查询缓存，若缓存未命中，查询数据库，将返回结果写入缓存。

      MQ 消息异步更新缓存。

* Redis 持久化，高可用集群

  * 面试官：关于 Redis 持久化方式能说说吗？有哪两种？

    **RDB（Redis DataBase）：**

    RDB 是 Redis 默认的持久化方案。在指定的时间间隔内，执行指定次数的写操作，则会将内存中的数据写入到磁盘中，即在指定目录下生成一个 dump.rdb 文件。Redis 重启会通过加载 dump.rdb 文件恢复数据。

    Redis 提供了 SAVE 和 BGSAVE 两个命令来生成 RDB 文件，区别是前者是阻塞的，后者是后台 fork 子进程进行，不会阻塞主进程处理命令请求。载入 RDB 文件不需要手工运行，而是 server 端自动进行，只要启动时检测到 RDB 文件存在 server 端便会载入 RDB 文件重建数据集。

    优点：

    适合大规模的数据恢复，如果业务对数据完整性和一致性要求不高，RDB 的启动速度更快；

    RDB 文件简洁，它保存了某个时间点的 Redis 数据集，适合用于做备份。你可以设定一个时间点对 RDB 文件进行归档，如果 1s 间隔保存一次快照，这样就能在需要的时候很轻易地把数据恢复到不同的版本；

    考虑到磁盘硬件故障问题，RDB 文件很适合用于灾备，因为单文件可以很方便地传输到另外的数据中心；

    RDB 的性能很好，需要进行持久化时，主进程会 fork 一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的 I/O 操作。

    缺点：

    数据的完整性和一致性不高，因为 SAVE 命令执行是有时间间隔的；

    备份时占用内存，因为 Redis 在备份时会创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍），最后再将临时文件替换之前的备份文件。

    **AOF（Append Only File）：**

    Redis 默认不开启。它的出现是为了弥补 RDB 的不足（RDB 可能丢失一个时间窗口的数据），所以它采用日志的形式来记录每个写操作，生成一个 appendonly.aof 文件，并将日志追加到文件末尾。Redis 重启时会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作，有点类似 MySQL 的 binlog。

    优点：

    AOF 策略最大限度地保证数据不丢失，数据的完整性和一致性更高。

    缺点：

    AOF 备份产生的 appendonly.aof 文件较大，数据恢复的时候也会比较慢，Redis 针对 AOF 文件大的问题提供重写的瘦身机制。

  * 面试官：关于 Redis 集群的设计，你了解如何搭建一个高可用集群吗？

    Redis Cluster 集群模式：Master Slave 模式中，Master 成为集群中至关重要的一个节点，Master 的稳定性决定整个系统的稳定性，为解决这一问题，Redis Cluster 应需求而生，Redis Cluster 是官方在 Redis 3.0 版本正式推出的高可用以及分布式的解决方案，内置数据自动分片机制，由多个 Redis 实例组成的整体，数据按照槽（slot）存储分布在多个 Redis 实例上，集群内部将所有的 key 映射到 16384 个 Slot 中。

    实现的功能：

    将数据分片到多个实例（按照 slot 存储）；

    集群节点宕掉会自动 failover；

    提供相对平滑扩容（缩容）节点。

* Redis 雪崩，穿透，击穿

  * 面试官：关于 Redis 雪崩，穿透，击穿你是怎么理解的？

    **雪崩：**

    雪崩就是指缓存中大批量热点数据过期后系统涌入大量查询请求，因为大部分数据在 Redis 层已经失效，请求渗透到数据库层，大批量请求犹如洪水一般涌入，引起数据库压力造成查询堵塞甚至宕机。

    解决办法：

    将缓存失效时间分散开，比如每个 key 的过期时间是随机的，防止同一时间大量数据过期现象发生，这样不会出现同一时间全部请求都落在数据库层。如果缓存和数据库是分布式部署，将热点数据均匀分布在不同 Redis 和数据库中，有效分担压力。

    简单粗暴，让 Redis 数据永不过期（如果业务准许）。

    **穿透：**

    穿透是指绕过 Reids，调用者发起的请求参数 key 在缓存和数据库中都不存在，通过不存在的 key，成功穿透到系统底层，大规模不断发起不存在的 key 检索请求导致系统压力过大最后故障。

    ```java
    if (redis.get(key) == null) {
        Object value = dao.query(key);
        redis.set(key);
    } else {
      return reids.get(key);
    }
    ```

    解决办法：

    布隆过滤器（Bloom Filter）；

    返回空值，遇到数据库和 Redis 都查询不到的值，在 Redis 里 set 一个 null value，过期时间很短，目的在于同一个 key 再次请求时直接返回 null，避免穿透。

    ```java
    try {
        Object value = dao.query(key);
        if (value == null) {
            redis.set(key, null, 20);
        } else {
            redis.set(key, value, 1000);
      }
    } catch(Exception e) {
        redis.set(key, null, 20);
    }
    ```

    **击穿：**

    击穿和穿透概念类似，一般是指一个 key 被穿透，这个 key 是热点 key，会有百万 QPS，如果这个 key 失效了，就像保险丝熔断，百万 QPS 直接压垮数据库。

    解决办法：

    业界比较常用的做法是使用 mutex。简单来说，就是在缓存失效的时候，不是立即去 load DB，而是先使用缓存工具的某些带成功操作返回值的函数（如 Redis 的 SETNX）去 set 一个 mutex key，当操作返回成功时，再进行 load DB 并回设缓存，否则，就重试整个 get 缓存的方法。

    ```java
    public String get(key) {
        String value = redis.get(key);
        if (value == null) {
            if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {
                value = db.get(key);
                redis.set(key, value, expire_secs);
                redis.del(key_mutex);
            } else {
                sleep(50);
                get(key);
            }
        } else {
            return value;
        }
    }
    ```

  * 布隆过滤器

    可以用于检索一个元素是否在一个集合中。Bloom Filter 检索一个元素是否在一个集合中有一定的错误率（很低），但不会漏判。如果判断一个 key 不在集合中，那一定不在；如果判断一个 key 存在，那不一定真的在。

    本质上布隆过滤器是一种概率型数据结构，特点是高效地插入和查询，可以用来告诉你“某样东西一定不存在或者可能存在“。相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。

    基本思想是利用一个足够好的 Hash 函数将一个字符串映射到二进制位数组中的某一位，这样不管字符串如何长，都只有一位，因此存储空间就极大的提升了。但是不管 Hash 函数如何高效，总是会存在 Hash 冲突，尤其是数据量变大的时候，而 Bloom Filter 利用多个不同的 Hash 函数来解决“冲突”，即一次采用多个 Hash 函数把数据映射到不同的位上，降低了冲突概率。

    Bloom Filter 有个缺点是不能删除数据，因为删除数据可能会影响到其它数据。

    Bloom Filter 十分适合海量数据去重、过滤，尤其是当检测的字符串比较大时，极大地节省内存和存储空间，同时查询效率也十分高效。如果只是在内存使用，直接使用 Guava 包的 API 即可，如果要用到分布式，结合 Redis 可以高效实现分布式的过滤效果。

* Redis 热点 Key 大 Value 解决方案

  * 面试官：你在项目中有没有遇到 Redis 热点数据问题，一般都是什么原因引起的？

    热点数据最大的问题会造成 Redis 集群负载不均衡（也就是数据倾斜）导致的故障，这些问题对于 Redis 集群都是致命打击。

    造成 Redis 集群负载不均衡故障的主要原因：

    高访问量的 Key，也就是热 Key，根据过去的维护经验一个 Key 访问的 QPS 超过 1000 就要高度关注了，比如热门商品，热门话题等；

    大 Value，有些 Key 访问 QPS 虽然不高，但是由于 Value 很大，造成网卡负载较大，网卡流量被打满，单台机器可能出现千兆 / 秒，IO 故障；

    热点 Key + 大 Value 同时存在，服务器杀手。

    热点 Key 或大 Value 会造成哪些故障：

    数据倾斜问题，大 Value 会导致集群不同节点数据分布不均匀，大量读写比例非常高的请求都会落到同一个 Redis Server 上，该 Redis 的负载就会严重升高，容易打挂；

    QPS 倾斜，分片上的 QPS 不均；

    大 Value 会导致 Redis 服务器缓冲区不足，造成 get 超时；

    由于 Value 过大，导致机房网卡流量不足；

    Redis 缓存失效导致数据库层被击穿的连锁反应。

  * 热点数据问题如何准确定位？

    提前获知法，根据业务统计可能会成为热点的数据，如促销活动商品，热门话题等；

    Redis 客户端收集法，调用端通过计数的方式统计 Key 的请求次数，代码侵入性强；

    Redis 集群代理层统计，像 Twemproxy、codis 这些基于代理的 Redis 分布式架构，有统一的入口，可以在 Proxy 层做收集上报。但是缺点很明显，并非所有的 Redis 集群架构都有 Proxy。

    Redis 服务端收集，Redis 提供了 monitor 命令，可以统计出一段时间内某 Redis 节点上的所有命令，分析热点 Key。在高并发条件下，会存在内存暴涨和 Redis 性能隐患，所以此种方法适合在短时间内使用。只能统计一个 Redis 节点的热点 Key，对于集群需要汇总统计，业务角度讲稍微麻烦一点。

    修改 Redis 源代码，Redis 4.0 为我们带来了许多新特性，其中便包括基于 LFU 的热点 Key 发现机制，有了这个新特性，我们就可以在此基础上实现热点 Key 的统计。

  * 如何治理热点数据问题？

    解决这个问题主要从两个方面考虑，第一是数据分片，让压力均摊到集群的多个分片上，防止单个机器打挂；第二是迁移隔离。

    Key 拆分，如果当前 Key 的类型是一个二级数据结构（哈希类型），该哈希元素个数较多，可以考虑将当前 Hash 进行拆分，这样该热点 Key 可以拆分为若干个新的 Key 分布到不同 Redis 节点上，从而减轻压力；

    迁移热点 Key，以 Redis Cluster 为例，可以将热点 Key 所在的 slot 单独迁移到一个新的 Redis 节点上，这样这个热点 Key 即使 QPS 很高，也不会影响到整个集群的其他业务，还可以定制化开发，热点 Key 自动迁移到独立节点上；

    热点 Key 限流：对于读命令我们可以通过迁移热点 Key 然后添加节点来解决，对于写命令我们可以通过单独针对这个热点 Key 来限流；

    增加本地缓存：对于数据一致性不是那么高的业务，可以将热点 Key 缓存到业务机器的本地缓存中。

  * 大 Value 如何解决？

    大 Value，String 类型 value > 10K，set、list、hash、zset 等集合数据类型中的元素个数 > 1000；

    超大 Value，String 类型 value > 100K，set、list、hash、zset 等集合数据类型中的元素个数 > 10000。

    由于 Redis 是单线程运行的，如果一次操作的 value 很大会对整个 Redis 的响应时间造成负面影响，所以业务上能拆则拆：

    一个较大的 key-value 拆分成几个 key-value，将操作压力平摊到多个 Redis 实例中，降低对单个 Redis 的 IO 影响；

    将拆分后的几个 key-value 存储在一个 hash 中，每个 field 代表一个具体的属性，使用 hget、hmget 来获取部分的 value，使用 hset，hmset 来更新部分属性；

    hash、set、zset、list 中存储过多的元素，可以将这些元素拆分。

* 本地缓存 Google Guava 的使用

  * 面试官：我们现在要做的系统是百万 QPS 级别，即使使用了 Redis，还是不够快、不够可靠，有没有别的办法让系统更快更可靠？

    双层缓存，本地缓存（[Guava Cache](https://github.com/google/guava/wiki/CachesExplained)） + Redis。

  * 面试官：都是内存里读写数据，为啥使用本地缓存就更快？

    Redis 相比本地缓存，多一次网络 IO。

### 异步调用篇

* 项目中为什么要使用消息队列

  大型分布式系统建设中，消息队列主要解决应用耦合、异步消息、流量削锋等问题，实现高性能、高可用、可伸缩和最终一致性架构，是大型分布式系统不可缺少的中间件。消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的，这样发布者和使用者都不用知道对方的存在。

  * 面试官：你在项目中使用过消息队列吗？

    ActiveMQ、RabbitMQ、RocketMQ、Kafka

  * 面试官：哪些业务场景使用了消息队列？

    一个服务所需要处理的工作越少，其性能自然越高。可以通过将部分操作异步化来减少需要同步进行的操作，进而提升服务的性能。异步化有两种方案：使用消息队列，使用多线程。

    ![日志收集](https://github.com/songor/interview/blob/master/picture/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86.jpg)

    采集日志是系统中经常被需要的功能，业务系统（如订单系统）流量高、响应时间要求高，如果想收集订单日志，收集日志的动作必然不可以影响订单主流程，采集日志过程就可以使用消息队列模型。

  * 面试官：为什么不使用线程池开启多线程呢，可同样达到异步的效果？

    使用消息队列有什么好处：

    异步处理模式：比如日志收集功能，订单系统是消息发送者，一行代码发送一条日志消息而无须等待。消息发送者将消息发送到一条虚拟的通道（主题或队列）上，日志存储服务作为消息接收者监听该通道，这样做的好处就是收集日志不会阻碍主流程，日志积压在消息队列里，日志服务可以慢慢消化，也无需很高的性能。

    应用系统解耦：订单服务和日志存储服务显然是两个服务，根据单一职责原则，订单服务只负责订单相关的工作，日志收集服务只负责收集日志，如果把这两件事通过线程池揉在一起，系统间界限就不明显了，做不到完全解耦。

    流量削峰：当订单服务接口在应对高峰流量时，如果日志服务接口处理能力有限，可以先将日志消息积压在队列里，后台慢慢处理，防止日志服务被打挂。

    发布 / 订阅（Producer-Consumer）：一条消息可以广播给任意多个收听方，Producer 只负责发送 Message，Consumer 可随意订阅 Message。就像广播一样，是系统之间跨机房跨机器通讯的主要手段。

    使用消息队列有什么缺点：

    消息丢失问题：任何系统不能保证万无一失，比如 Producer 发出了 10000 条消息，Consumer 只收到了 9999 条消息，Consumer 能否接受丢一条？

    消息重复问题：如 Producer 发出了 10000 条消息，Consumer 收到了 10001 条消息，有一条是重复的，业务能否接受一条重复的消息？

    消息顺序问题：如 Producer 发送顺序是 123，Consumer 收到顺序是 132，要考虑消费端是否对顺序敏感。

    一致性问题：如消息丢失问题真的发生且无法找回，会造成两个系统的数据最终不一致。如果消息延迟，会造成短暂不一致。

* 全面了解 Kafka 的使用与特性

  * 面试官：简述下 Kafka 架构中比较重要的关键字

    Producer：消息的生产方，如支付系统确认用户已经支付，支付系统要通知订单系统和物流系统，支付系统就是生产者。

    Consumer：消息的接收方，订单系统和物流系统。

    Topic：每条发布到 MQ 集群的消息都有一个类别，这个类别被称为 Topic。可以理解成一类消息的名字，所有的消息都有 Topic 作为单位进行归类。

    Partition：Kafka 物理上分区的概念，每个 Topic 会分散在一个或多个 Partition，一个 Topic 的数据太大了，就分成小片。Kafka 为分区引入多副本模型，副本之间采用“一个 Leader 多个 Follower”的设计，通过多副本实现故障自动转移，保证可用性。

    Broker：可以理解成一个服务器节点，集群包含一个或多个服务器，这种服务器被称为 Broker。

    Kafka Cluster：集群就是 Broker 的集合，多个 Broker 组成一个高可用集群。

  * 为什么要选择 Kafka 呢？

    相比同类中间件 RabbitMQ 或 ActiveMQ，Kafka 支持批量拉取消息，大大增加了 Kafka 的消息吞吐量。

    支持多种发送场景：发送并忘记，同步发送，异步发送 + 回调函数。如果业务要求消息必须按顺序发送，可以使用同步发送，并且只能在一个 Partition 上。如果业务只关注消息的吞吐量，容许少量消息发送失败，也不关心消息的发送顺序，那么可以使用发送并忘记的方式。如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步 + 回调的方式来发送消息。

    Kafka 集群可以透明地扩展，增加新的服务器进入集群。

  * 面试官：为什么 Kafka 的吞吐量远高于其他同类中间件？

    利用了磁盘连续读写性能远远高于随机读写的特点，内部采用消息的批量处理，zero-copy 机制，数据的存储和获取是本地磁盘顺序批量操作，具有 O(1) 的复杂度，消息处理的效率很高。

    分布式并行处理，将一个 Topic 拆分多个 Partition，Kafka 读写的单位是 Partition。但是这里有个前提，不同 Partition 需要位于不同的磁盘（可以在同一个机器）。如果多个 Partition 位于同一个磁盘，那么意味着有多个进程同时对一个磁盘的多个文件进行读写，使得操作系统会对磁盘读写进行频繁调度，也就破坏了磁盘读写的连续性。

* 如何解决消息重复、保证消息顺序问题

  * 面试官：你有考虑过消息重复问题怎么解决吗？

    消费端接口幂等，根据用户订单号或者流水号做强幂等。

    ```java
    List<UserPointHistory> lists = userPointDao.queryHistory(orderId);
    if (CollectionUtils.isNotEmpty(lists)) {
        userPoint.add(pointCount, orderId);
        userPoint.addHistory(orderId);
    } else {
        return null;
    }
    ```

  * 面试官：在多集群消息架构中，如果消费端要求接收到的消息是有序的，怎么解决消息顺序消费问题？

    让同一个 Topic 消息不分区，且单线程：

    生产端同步发送消息，消息 1 确定发送成功后再发送消息 2，不能异步，保证消息顺序入队。

    Producer -> MQ Server -> Consumer 一对一关系，一对一服务，保证消息是按照顺序消费的。那么问题来了，任意一个环节出现问题，整个链路都被阻塞了；单通道模型性能成为瓶颈。

    Topic 不分区，让同一个 Topic 消息都入一个队列。在分布式环境下如果同一个 Topic 消息进入多个分区，那多个分区之间肯定无法保证消息顺序。

    保证消费端是串行消费，禁止使用多线程。

  * 面试官：如何做到 Topic 不分区，能举例说明一下吗？

    RocketMQ：RocketMQ 提供了 MessageQueueSelector 队列选择机制，我们可以把 Topic 用 Hash 取模法，相同 Topic 的 Hash 值肯定是一样的，让同一个 Topic 消息入同一个队列中，再使用同步发送，这样就能保证消息在一个分区有序了。

    Kafka： Kafka 可以把 max.in.flight.requests.per.connection 参数设置成 1，这样就可以保证同一个 Topic 在同一个分区内了。

### 数据存储篇

* 数据库如何做分库分表，读写分离

  * 面试官：说一说你项目里为什么要分库分表？在什么情况下会使用分库分表？

    一句话概括就是为了提高数据库的读写效率，更重要的是提高读效率，提高查询性能，解决数据量过大从而导致的数据库性能下降的问题。

    分库：提高架构可用性，减少单点故障，有效分担一个库的压力。只分库不分表，常用于读写分离场景，一主多从，主库负责写，从库用于读，从库同步更新主库数据，保持数据一致，适用于写入少读取多的场景。

    分表：把数据分片拆分，多个表数据减少，insert 插入速度提高，读取速度也得以提高。

  * 怎么做分库分表？

    不分库只分表：将数据库中的 user 表（3000w 行数据）拆分为 2 个分表，user_0，user_1，user_2，每个分表里有 1000w 行数据，这 3 个表还位于同一个库中，属于水平切分。

    只分库不分表：将数据库拆分为 db_0，db_1，db_2 三个库，同时在 db_0，db_1，db_2 库中各自新建一个 user 表，db_0.user，db_1.user，db_2.user 表中各自只存原来的 db.user 表中的部分数据，每个库里有 1000w 行数据。

    既分库又分表：将数据库拆分为 db_0，db_1，db_2 三个库，db_0 中包含 user_0，user_1 两个分表，db_1 中包含 user_2，user_3 两个分表，db_2 中包含 user_4，user_5 两个分表，这样每张表里有 500w 行数据。

  * 面试官：使用什么策略分库分表？

    对 key 取模法，可以哈希后再取模 Hash(userId) % n；

    RANGE 分区；

    时间分区，适用于订单数据拆分，如按天分表，按月分表，按年分表，时间越久的数据被查询的概率越低，类似冷热数据分离。

    对 key 取模法有一个缺点（估算好数据增量，合理做好规划），如果 n 变大，那么之前已经计算好的取模值会变，已经存在的数据要重新分片，将面临大量额外的数据迁移工作，如果这个 n 变动频繁，考虑一致性 hash 算法。

  * 深入分析

    表数目决策：一般情况下，建议单个物理分表的容量不超过 1000 万行数据，通常可以预估 2 到 5 年的数据增长量，用估算出的总数据量除以总的物理分库数，再除以建议的最大数据量 1000 万，即可得出每个物理分库上需要创建的物理分表数。

    库数目决策：按照存储容量来计算，(3 到 5 年内的存储容量) / 单个库建议存储容量（300G 以内）。最差情况，所有的分库都共享数据库机器。最优情况，每个分库都独占一台数据库机器。一般建议一个数据库机器上存放 8 个数据库分库。

    分库分表会带来哪些挑战：

    分布式 ID 问题：在分库分表后，我们不能再使用 MySQL 的自增主键，因为在插入记录的时候，不同的库生成的记录的自增 ID 会出现冲突，因此需要有一个全局的 ID 生成器，系统需要额外的可靠分布式 ID 生成器服务；

    分布式事务问题：分布式事务是分库分表绕不过去的一个坎，因为涉及到了同时更新多个数据库，如何保证要么同时成功，要么同时失败。关于分布式事务，MySQL 支持 XA 事务，但是效率较低。柔性事务是目前比较主流的方案，柔性事务包括，最大努力通知型、可靠消息最终一致性方案以及 TCC 两阶段提交。但是无论 XA 事务还是柔性事务，实现起来都是非常复杂的；

    最低代价动态扩容问题：一致性 hash 算法，移动最少的数据扩容分片数量；

    分库分表后的 Join 操作：一般情况下，分库分表后就不能再和单库单表一样进行 Join 操作，应尽量避免这样的查询，可以采用字段冗余。

    分库分表常用中间件：MyCAT

* 