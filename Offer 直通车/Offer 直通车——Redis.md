# Offer 直通车——Redis

* Memcache 和 Redis

  * Memcache，代码层次类似于 Hash

    支持简单的数据类型、不支持数据持久化存储、不支持主从、不支持分片

  * Redis

    数据类型丰富、支持数据磁盘持久化存储、支持主从、支持分片

* 为什么 Redis 能这么快（100000+ QPS）

  完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高

  数据结构简单，对数据操作也简单

  采用单线程

  使用多路复用 IO 模型，非阻塞 IO

* 多路复用 IO 模型

  FD（File Descriptor，文件描述符）：一个打开的文件通过唯一的描述符进行引用

  Select 系统调用：Select 方法能够监控多个文件描述符的可读、可写情况

  Redis 采用的多路复用 IO 函数（epoll / kqueue / evport / select）：

  因地制宜，优先选择时间复杂度为 O(1) 的多路复用 IO 函数作为底层实现

  以时间复杂度为 O(n) 的 select 作为保底

  基于 react 设计模式监听 IO 事件

* Redis 数据类型

  String：二进制安全

  ```c
  struct sdshdr {
      int len;
      int free;
      char buf[];
  };
  ```

  Hash：适合用于存储对象

  List

  Set

  Sorted Set：Double 类型的权重参数 Score

  HyperLogLog：是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的，并且是很小的。因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

  Geo：地理位置

* 海量数据里查询某一固定前缀的 key

  KEYS pattern：查找所有符合给定模式 pattern 的 key

  SCAN cursor [MATCH pattern] [COUNT count]

  scan 0 match prefix\* 10

  基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程。

  以 0 作为游标开始一次新的迭代，直到命令返回游标 0 完成一次遍历（full iteration）。

  一次返回的数量不可控（不保证每次执行都返回某个给定数量的元素），只能是大概率符合 count 参数。

  SCAN 命令的回复是一个包含两个元素的数组， 第一个数组元素是用于进行下一次迭代的新游标， 而第二个数组元素则是一个数组， 这个数组中包含了所有被迭代的元素。

* 如何实现分布式锁

  * 分布式锁需要解决的问题

    互斥性、安全性、死锁、容错

  * SETNX key value

    如果 key 不存在，则创建并赋值

  * 解决 SETNX 长期有效的问题

    EXPIRE key seconds（原子性得不到满足）

  * SET key value [EX seconds] [PX milliseconds] [NX|XX]

    EX seconds：将键的过期时间设置为 seconds 秒

    PX milliseconds：将键的过期时间设置为 milliseconds 毫秒

    NX：只在键不存在时，才对键进行设置操作

    XX：只在键已经存在时，才对键进行设置操作

  * 大量的 key 同时过期

    由于清除大量的 key 很耗时，会出现短暂的卡顿现象，在设置 key 的过期时间的时候，给每个 key 加上随机值。

* 异步队列

  * 使用 List 作为队列，RPUSH 生产消息，LPOP 消费消息

    通过在应用层引入 sleep 机制去调用 LPOP 重试

  * BLPOP key [key...] timeout

    阻塞直到队列有消息或者超时

  * pub / sub：主题订阅者模式

    subscribe topic / publish topic "Hello World"

    消息的发布是无状态的，无法保证可达

* 持久化

  * RDB

    RDB 持久化是通过快照的方式，即在指定的时间间隔内将内存中的数据集快照写入磁盘。在创建快照之后，用户可以备份该快照，可以将快照复制到其他服务器以创建相同数据的服务器副本，或者在重启服务器后恢复数据。RDB 是 Redis 默认的持久化方式。

    * redis.conf

      save 900 1：当时间到 900 秒时，如果至少有 1 个 key 发生变化，就会自动触发 bgsave 命令创建快照

      save 300 10：当时间到 300 秒时，如果至少有 10 个 key 发生变化，就会自动触发 bgsave 命令创建快照

      save 60 10000：当时间到 60 秒时，如果至少有 10000 个 key 发生变化，就会自动触发 bgsave 命令创建快照

      stop-writes-on-bgsave-error yes：快照功能开启，后台持久化操作失败，Redis 则会停止接受更新操作

      rdbcompression yes：在进行镜像备份时，是否进行压缩。yes 压缩，但是需要一些 cpu 的消耗。no 不压缩，需要更多的磁盘空间

      save ""

    * 创建 RDB 文件

      SAVE：阻塞 Redis 的服务器进程，直到 RDB 文件被创建完毕

      BGSAVE：Fork 出一个子进程来创建 RDB 文件，不阻塞服务器进程（lastsave：返回最近一次 Redis 成功将数据保存到磁盘上的时间，以 UNIX 时间戳格式表示）

    * 自动触发 RDB 持久化的方式

      根据 redis.conf 配置里的 SAVE m n 定时触发（BGSAVE）

      主从复制时，主节点自动触发

      Debug Reload：save 当前的 rdb 文件，并清空当前数据库，重新加载 rdb，加载与启动时加载类似，加载过程中只能服务部分只读请求（比如 info、ping 等）

      执行 Shutdown 且没有开启 AOF

    * BGSAVE 原理

      系统调用 fork()，创建进程，实现了 Copy-on-Write（父子进程共享物理页面）：

      如果有多个调用者同时请求相同的资源（如内存或磁盘上的数据存储），它们会获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本给该调用者，而其他调用者所见到的最初的资源仍然保持不变。

    * 缺点

      内存数据的全量同步，数据量大会由于 IO 而严重影响性能

      可能会因为 Redis down 而丢失从当前至最近一次快照期间的数据

  * AOF

    AOF 持久化会把被执行的写命令写到 AOF 文件的末尾，记录数据的变化。默认情况下，Redis 是没有开启 AOF 持久化的，开启后，每执行一条更改 Redis 数据的命令，都会把该命令追加到 AOF 文件中，这会降低 Redis 的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高 AOF 的性能。

    记录下除了查询以外的所有变更数据库状态的指令，以 append 形式追加保存到 AOF 文件中（增量）。

    * redis.conf

      appendonly yes：开启 AOF 持久化

      appendfilename "appendonly.aof"：AOF 持久化的文件名

      appendfsync always：将 aof_buf 缓冲区的所有内容写入并同步到 AOF 文件，每个写命令同步写入磁盘

      appendfsync everysec：将 aof_buf 缓存区的内容写入 AOF 文件，每秒同步一次，该操作由一个线程专门负责

      appendfsync no：将 aof_buf 缓存区的内容写入AOF文件，什么时候同步由操作系统来决定

      当 AOF 文件的体积大于 64MB，且 AOF 文件的体积比上一次重写后的体积大了一倍（100%）时，会执行 bgrewriteaof 命令：

      auto-aof-rewrite-percentage 100

      auto-aof-rewrite-min-size 64mb

    * 实现

      AOF 需要记录 Redis 的每个写命令，步骤为：命令追加（append）、文件写入（write）和文件同步（sync）。

      命令追加（append）：

      开启 AOF 持久化功能后，服务器每执行一个写命令，都会把该命令以协议格式先追加到 aof_buf 缓存区的末尾，而不是直接写入文件，避免每次有命令都直接写入硬盘，减少硬盘 IO 次数。

      文件写入（write）和文件同步（sync）：

      对于何时把 aof_buf 缓冲区的内容写入保存在 AOF 文件中，Redis 提供了多种策略：appendfsync always、appendfsync everysec、appendfsync no，appendfsync 选项的默认配置为 everysec，即每秒执行一次同步。

      关于 AOF 的同步策略是涉及到操作系统的 write 函数和 fsync 函数的：

      为了提高文件写入效率，在现代操作系统中，当用户调用 write 函数，将一些数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区的空间被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里。

      这样的操作虽然提高了效率，但也为数据写入带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了 fsync 、fdatasync 同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性。

      从上面的介绍我们知道，我们写入的数据，操作系统并不一定会马上同步到磁盘，所以 Redis 才提供了 appendfsync 的选项配置。当该选项时为 always 时，数据安全性是最高的，但是会对磁盘进行大量的写入，Redis 处理命令的速度会受到磁盘性能的限制。appendfsync everysec 选项则兼顾了数据安全和写入性能，以每秒一次的频率同步 AOF 文件，即便出现系统崩溃，最多只会丢失一秒内产生的数据。如果是 appendfsync no 选项，Redis 不会对 AOF 文件执行同步操作，而是由操作系统决定何时同步，不会对 Redis 的性能带来影响，但假如系统崩溃，可能会丢失不定数量的数据。

    * 日志重写解决 AOF 文件不断增大的问题（aofrewrite）

      重写会有大量的写入操作，所以服务器进程会 fork 一个子进程来创建一个新的 AOF 文件（AOF 文件重写并不需要对现有的 AOF 文件进行任何读取、分享和写入操作，而是通过读取服务器当前的数据库状态来实现的）

      在重写期间，服务器进程继续处理命令请求，如果有写入的命令，追加到 aof_buf 的同时，还会追加到 aof_rewrite_buf AOF 重写缓冲区

      当子进程完成重写之后，会给父进程一个信号，然后父进程会把 AOF 重写缓冲区的内容写进新的 AOF 临时文件中，再对新的 AOF 文件改名完成替换，这样可以保证新的 AOF 文件与当前数据库数据的一致性

  * RDB 和 AOF 区别

    RDB：全量数据快照，文件小（压缩过的非常紧凑的文件，保存着某个时间点的数据集），恢复快（适合做数据的备份，灾难恢复），最大化 Redis 性能（服务器进程只需 fork 一个子进程来完成 RDB 文件的创建，父进程不需要做 IO 操作）；无法保存最近一次快照之后的数据

    AOF：可读性高（Redis 的序列化协议 RESP），适合保存增量数据，数据不易丢失；文件体积大，恢复时间长

  * 如何选择 RDB 和 AOF

    如果是数据不那么敏感，且可以从其他地方重新生成补回的，那么可以关闭持久化

    如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用 RDB

    如果是用做内存数据库，要使用 Redis 的持久化，建议是 RDB 和 AOF 都开启，或者定期执行 bgsave 做快照备份，RDB 方式更适合做数据的备份，AOF 可以保证数据的不丢失

  * RDB-AOF 混合持久化

    BGSAVE 做镜像全量持久化，AOF 做增量持久化

* Pipeline

  Pipeline 和 Linux 的管道类似

  Redis 基于请求、响应模型，单个请求处理需要一一应答（阻塞）

  Pipeline 批量执行指令，节省多次 IO 往返的时间

  有顺序依赖的指令建议分批发送

* 主从同步

  主从同步有同步（全同步）和命令传播（增量同步）两个步骤

  同步：将从服务器的数据库状态更新成主服务器当前的数据库状态

  命令传播：在完成同步之后，也许主服务器马上就接受到了新的写命令，执行完该命令后，主从的数据库状态又不一致。为了再次让主从数据库状态一致，主服务器就需要向从服务器执行命令传播操作 ，即把刚才造成不一致的写命令，发送给从服务器去执行。从服务器执行完成之后，主从数据库状态就又恢复一致了。

  * 全同步过程

    Slave 发送 sync 命令到 Master

    Master 启动一个后台进程，将 Redis 中的数据快照保存到文件中（BGSAVE）

    Master 将保存数据快照期间接收到的写命令缓存起来

    Master 完成写文件操作后，将该文件发送给 Slave

    Slave 使用新的 RDB 文件替换掉旧的 RDB 文件

    Master 将这期间收集的增量写命令发送给 Slave

  * 增量同步过程

    Master 接收到用户的操作指令，判断是否需要传播到 Slave

    将操作记录追加到 AOF 文件

    将操作传播到其他 Slave：对齐主从库；往响应缓存写入指令

    将缓存中的数据发给 Slave

* Redis Sentinel

  解决主从同步 Master 宕机后的主从切换问题（主节点的自动故障转移）

  Redis Sentinel 是一个分布式架构，包含若干个 Sentinel 节点和 Redis 数据节点，每个 Sentinel 节点会对数据节点和其余 Sentinel 节点进行监控，当发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，他还会选择和其他 Sentinel 节点进行“协商”，当大多数的 Sentinel 节点都认为主节点不可达时，他们会选举出一个 Sentinel 节点来完成自动故障转移工作，同时将这个变化通知给 Redis 应用方。整个过程完全自动，不需要人工介入，所以可以很好解决 Redis 的高可用问题。

  监控：检查主从服务器是否运行正常

  报警：通过 API 向管理员或者其他应用程序发送故障通知

  自动故障迁移：主从切换，当主节点宕机时，哨兵从原主节点下的所有可用从节点中选举出一个作为主节点，原主节点降为从节点，并将其他从节点的主节点配置改为指定新主节点

  配置中心：客户端连接到 Sentinel 上获取当前的 Redis Master 地址

* 流言协议 Gossip（在杂乱无章中寻求一致）

  每个节点都随机地与对方通信，最终所有节点的状态达成一致

  种子节点定期随机向其他节点发送节点列表以及需要传播的消息

  不保证信息一定会传递给所有节点，但是最终会趋于一致

* Redis 集群

  集群由多个节点（Node）组成，Redis 的数据分布在这些节点中。

  集群中的节点分为主节点和从节点，只有主节点负责读写请求和集群信息的维护，从节点只进行主节点数据和状态信息的复制。

  集群的作用，可以归纳为两点：

  数据分区（或称数据分片）是集群最核心的功能：集群将数据分散到多个节点，一方面突破了 Redis 单机内存大小的限制，存储容量大大增加。另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。

  高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似），当任一节点发生故障时，集群仍然可以对外提供服务。

  * 如何从海量数据里快速找到所需

    分片：按照某种规则去划分数据，分散存储在多个节点上（常规的按照哈希划分无法实现节点的动态增减）

    一致性哈希算法：对 2^32 取模，将哈希值空间组织成虚拟的圆环，Node 节点 hash 到环上（IP），并根据 key 使用相同的函数 hash 计算出哈希值，顺时针找到 Node 节点

    Hash 环的数据倾斜问题（服务器节点少的情况）：引入虚拟节点（对每一个服务器节点计算多个哈希，需要虚拟节点和 Node 节点的映射）

* Redis 高可用技术

  持久化：持久化是最简单的高可用方法（有时甚至不被归为高可用的手段），主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。

  复制：复制是高可用 Redis 的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。

  哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。

  集群：通过集群，Redis 解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。